<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rstats | Josh Duncan</title>
    <link>/tag/rstats/</link>
      <atom:link href="/tag/rstats/index.xml" rel="self" type="application/rss+xml" />
    <description>rstats</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 26 Mar 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>rstats</title>
      <link>/tag/rstats/</link>
    </image>
    
    <item>
      <title>Market Demand with Instrumental Variables</title>
      <link>/post/2019-03-26_market-dem-with-iv/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-03-26_market-dem-with-iv/</guid>
      <description>


&lt;div id=&#34;overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;Skipper Seabold, a well known contributor to the PyData community, recently gave a &lt;a href=&#34;https://youtu.be/kTo16ieMCi8&#34;&gt;talk&lt;/a&gt; titled “What’s the Science in Data Science?”. His talk presents several methods commonly used in econometrics that could benefit the field of data science if more widely adopted. Some of the methods were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instrumental Variables&lt;/li&gt;
&lt;li&gt;Matching&lt;/li&gt;
&lt;li&gt;Difference-in-Differences&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From what I gather, these modeling techniques are popular for discovering causal relationships in observational studies. When an RCT (randomized control trial) is unreasonable then these techniques give us an alternative approach.&lt;/p&gt;
&lt;p&gt;I’ll be exploring one of these methods called &lt;em&gt;Instrumental Variables&lt;/em&gt; (or IV). An example use case from Skipper’s talk was a &lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/jep.20.2.207&#34;&gt;study&lt;/a&gt; on the &lt;strong&gt;Fulton Fish Market&lt;/strong&gt; in NYC.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26-market-price-with-instrumental-variables_files/fulton.jpg&#34; alt=&#34;drawing&#34; width=&#34;50%&#34;/&gt;&lt;/p&gt;
&lt;p&gt;The referenced study estimates the demand curve for fish at the market. Finding the demand curve is unfortunately not as simple as regressing quantity on price. The relationship between price and the quantity of fish sold is not exclusive to demand but includes supply effects at the market. We’ll be using IV to account for supply effects to isolate the demand effects.&lt;/p&gt;
&lt;p&gt;In this blog post I’ll be reproducing a portion of this analysis using R, packages of the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt;, and the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; package in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;I discovered data related to this study at the following website:
&lt;a href=&#34;http://people.brandeis.edu/~kgraddy/data.html&#34; class=&#34;uri&#34;&gt;http://people.brandeis.edu/~kgraddy/data.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Bringing this data into R is very simple. The linked dataset appears to be the cleaned and transformed data used within the paper. Let’s read it into our R environment and take a look:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

fulton &amp;lt;- read_tsv(&amp;quot;http://people.brandeis.edu/~kgraddy/datasets/fish.out&amp;quot;)
fulton&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 111 x 16
##     day1  day2  day3  day4   date stormy mixed   price   qty rainy  cold
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1     1     0     0     0 911202      1     0 -0.431   8.99     1     0
##  2     0     1     0     0 911203      1     0  0       7.71     0     0
##  3     0     0     1     0 911204      0     1  0.0723  8.35     1     1
##  4     0     0     0     1 911205      1     0  0.247   8.66     0     1
##  5     0     0     0     0 911206      1     0  0.664   7.84     0     1
##  6     1     0     0     0 911209      0     0 -0.207   9.30     0     0
##  7     0     1     0     0 911210      0     1 -0.116   8.92     0     0
##  8     0     0     1     0 911211      0     0 -0.260   9.11     1     0
##  9     0     0     0     1 911212      0     1 -0.117   8.31     0     0
## 10     0     0     0     0 911213      0     0 -0.342   9.21     0     0
## # … with 101 more rows, and 5 more variables: windspd &amp;lt;dbl&amp;gt;,
## #   windspd2 &amp;lt;dbl&amp;gt;, pricelevel &amp;lt;dbl&amp;gt;, totr &amp;lt;dbl&amp;gt;, tots &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a quick description of the variables we will be using for this work:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th&gt;Units&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;qty&lt;/td&gt;
&lt;td&gt;log(pounds)&lt;/td&gt;
&lt;td&gt;The total amount of fish sold on a day&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;price&lt;/td&gt;
&lt;td&gt;log($/lb)&lt;/td&gt;
&lt;td&gt;Average price for the day&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;day1-day4&lt;/td&gt;
&lt;td&gt;dummy var&lt;/td&gt;
&lt;td&gt;Monday-Thurs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;cold&lt;/td&gt;
&lt;td&gt;dummy var&lt;/td&gt;
&lt;td&gt;Weather on shore&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;rainy&lt;/td&gt;
&lt;td&gt;dummy var&lt;/td&gt;
&lt;td&gt;Rain on shore&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;stormy&lt;/td&gt;
&lt;td&gt;dummy var&lt;/td&gt;
&lt;td&gt;Wind and waves off shore (a 3-day moving average)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The paper informs the reader that transactions recorded are of a particular fish species called Whiting. We can get a feel for the total amount of Whiting being sold by reproducing Figure &lt;code&gt;2&lt;/code&gt; from the paper.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# fixing the date column 
fulton %&amp;gt;% 
  mutate(
    date = as.character(date),
    date = parse_date(date, format = &amp;quot;%y%m%d&amp;quot;)
  ) %&amp;gt;% 
  ggplot(aes(x = date, y = exp(qty))) +
    geom_col() +
    labs(
      title = &amp;quot;Figure 2&amp;quot;,
      subtitle = &amp;quot;Daily Volumes of Whiting&amp;quot;,
      x = &amp;quot;Date (December 2, 1991-May 8, 1992)&amp;quot;,
      y = &amp;quot;Quantity (pounds)&amp;quot;
      )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-2-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Reproducing this figure gave me confidence that I had the correct data to reproduce the analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;demand-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Demand Curve&lt;/h2&gt;
&lt;p&gt;The naive approach to finding the relationship between price and demand (the demand curve) would be to regress quantity on price:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(fulton, aes(x = price, y = qty)) + 
  geom_point() + 
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-3-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But would this be the demand curve? No, it actually wouldn’t be. According to intro economics, each one of the points in the plot above is the result of the intersection of both a supply and demand curve. Something like this &lt;a href=&#34;https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/&#34;&gt;figure&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26-market-price-with-instrumental-variables_files/supply-demand-intersection-simple-1.png&#34; alt=&#34;drawing&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;
&lt;p&gt;So how does the author go about estimating a more accurate representation of the demand curve? How do you isolate the demand effects from the supply? Well, it’s in the title of this post: &lt;strong&gt;Instrumental Variables&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Skipper’s presentation explained IV as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We can replace &lt;em&gt;X&lt;/em&gt; with &lt;strong&gt;“instruments”&lt;/strong&gt; that are &lt;strong&gt;correlated with X&lt;/strong&gt; but &lt;strong&gt;not caused by Y&lt;/strong&gt; or that &lt;strong&gt;affect Y&lt;/strong&gt; but &lt;em&gt;only&lt;/em&gt; &lt;strong&gt;through X&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;regressions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regressions&lt;/h2&gt;
&lt;p&gt;The paper includes a table of estimated coefficients shown here:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26-market-price-with-instrumental-variables_files/table-2.png&#34; alt=&#34;drawing&#34; width=&#34;80%&#34;/&gt;&lt;/p&gt;
&lt;p&gt;I’ll be reproducing this table but with Bayesian estimation. A nice benefit of using Bayesian estimation is that our estimated model includes distributions for each of our parameters. We’ll be visualizing these distributions for comparing results to the table above.&lt;/p&gt;
&lt;div id=&#34;ols-ordinary-least-squares-reproduced&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;OLS (Ordinary Least Squares) Reproduced&lt;/h3&gt;
&lt;p&gt;First, let’s perform the classic linear regression. We can use the &lt;code&gt;brm&lt;/code&gt; function in the &lt;code&gt;brms&lt;/code&gt; package as a drop in replacement for R’s linear model function &lt;code&gt;lm&lt;/code&gt;. However, the estimation process of &lt;code&gt;lm&lt;/code&gt; and &lt;code&gt;brm&lt;/code&gt; are quite different. The &lt;code&gt;lm&lt;/code&gt; function is using OLS and the &lt;code&gt;brms&lt;/code&gt; package is performing Bayesian estimation using a &lt;a href=&#34;https://arxiv.org/abs/1701.02434&#34;&gt;form&lt;/a&gt; of Markov Chain Monte Carlo (MCMC).&lt;/p&gt;
&lt;p&gt;Starting with column &lt;code&gt;1&lt;/code&gt; of table &lt;code&gt;2&lt;/code&gt; we estimate the coefficients with only &lt;code&gt;qty&lt;/code&gt; and &lt;code&gt;price&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)
library(tidybayes)
library(ggridges)

# column 1 in table 2
fit1 &amp;lt;- brm(qty ~ price, data = fulton, refresh = 0)

fit1 %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  ggplot(aes(x = b_price)) +
    geom_density_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-4-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;brms&lt;/code&gt; package provides an abstraction layer to the &lt;code&gt;Stan&lt;/code&gt; probabilistic programming language. So if you’re curious what the “uninformative” priors that I breezed over actually are, take a look at the generated code with the &lt;code&gt;stancode&lt;/code&gt; function. Here is an excerpt of the stan code generated for the model above:&lt;/p&gt;
&lt;pre class=&#34;stan&#34;&gt;&lt;code&gt;model {
  vector[N] mu = temp_Intercept + Xc * b;
  // priors including all constants
  target += student_t_lpdf(temp_Intercept | 3, 9, 10);
  target += student_t_lpdf(sigma | 3, 0, 10)
    - 1 * student_t_lccdf(0 | 3, 0, 10);
  // likelihood including all constants
  if (!prior_only) {
    target += normal_lpdf(Y | mu, sigma);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moving to column &lt;code&gt;2&lt;/code&gt; of table &lt;code&gt;2&lt;/code&gt; we estimate the model including the dummy &lt;code&gt;day&lt;/code&gt; variables, &lt;code&gt;cold&lt;/code&gt;, and &lt;code&gt;rainy&lt;/code&gt; variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# column 2 in table 2
fit1_full &amp;lt;- brm(
  qty ~ price + day1 + day2 + day3 + day4 + cold + rainy,
  data = fulton,
  refresh = 0
)

# a plot of parameter estimates
fit1_full %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  gather(b_price:b_rainy, key = &amp;quot;coef&amp;quot;, value = &amp;quot;est&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = est, y = coef)) +
    geom_density_ridges()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-6-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that the estimated coefficient for price in this context is the same for both the simple linear regression and the regression accounting for weekday and onshore weather.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;iv-reproduced&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;IV Reproduced&lt;/h3&gt;
&lt;p&gt;Before performing the estimation I wanted to add a quote from the paper. I thought Kathryn Graddy explained the IV estimation well:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;That is, first a regression is run with log price as the dependent variable and the storminess of the weather as the explanatory variable. This regression seeks to measure the variation in price that is attributable to stormy weather. The coefficients from this regression are then used to predict log price on each day, and these predicted values for price are inserted back into the regression.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kathryn mentions two steps here:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A regression with log price and storminess&lt;/li&gt;
&lt;li&gt;Using coefficients from step &lt;code&gt;1&lt;/code&gt;, predict log price and place the predicted values back into the second regression.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A simple diagram of this two step process is generated below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggdag)

dagify(
  qty ~ price, 
  price ~ stormy
  ) %&amp;gt;% 
  ggdag(seed = 12) +
  theme(panel.background = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-7-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s perform the estimation. This is possible with the &lt;code&gt;brms&lt;/code&gt; package and its ability to specify multivariate response models. We’ll piece it together with two separate formulas defined in the &lt;code&gt;bf&lt;/code&gt; function calls below.&lt;/p&gt;
&lt;p&gt;The first estimation will be for column &lt;code&gt;3&lt;/code&gt; of table &lt;code&gt;2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# measure variation in price attributable to stormy weather
fit2a &amp;lt;- bf(price ~ stormy)
# estimate demand
fit2b &amp;lt;- bf(qty ~ price)

# column 3 in table 2
fit2 &amp;lt;- brm(fit2a + fit2b, data = fulton, refresh = 0)

fit2 %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  ggplot(aes(x = b_qty_price)) +
    geom_density_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-8-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And lastly we’ll estimate the IV with the remaining variables (column &lt;code&gt;4&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# visual representation of the estimation
dagify(
  qty ~ price + day1 + day2 + day3 + day4 + cold + rainy, 
  price ~ stormy
  ) %&amp;gt;% 
  ggdag(seed = 9) +
  theme(panel.background = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-9-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add additional demand specific variables
fit2b_full &amp;lt;- bf(qty ~ price + day1 + day2 + day3 + day4 + cold + rainy)

# column 4 in table 2
fit2_full &amp;lt;- brm(fit2a + fit2b_full, data = fulton, refresh = 0)

fit2_full %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  gather(b_qty_price:b_qty_rainy, key = &amp;quot;coef&amp;quot;, value = &amp;quot;est&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = est, y = coef)) +
    geom_density_ridges()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-10-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One thing that I think is particularly interesting about the distributions above is the uncertainty of the price coefficient. We can clearly see that the parameter’s distribution with IV is much wider than our classic linear regression. Here we are seeing the uncertainty of our first model (&lt;code&gt;price ~ storminess&lt;/code&gt;) propagating to our second model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-demand-curve&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing the Demand Curve&lt;/h3&gt;
&lt;p&gt;Now we can plot the demand curve with isolated demand effects. I’ll use the first IV estimation with only &lt;code&gt;qty&lt;/code&gt;, &lt;code&gt;price&lt;/code&gt;, and &lt;code&gt;stormy&lt;/code&gt; variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fulton %&amp;gt;% 
  add_predicted_draws(fit2) %&amp;gt;% 
  filter(.category == &amp;quot;qty&amp;quot;) %&amp;gt;% 
  ggplot(aes(x = price, y = qty)) +
  stat_lineribbon(
    aes(y = .prediction), 
    .width = c(.99, .95, .8, .5), 
    color = &amp;quot;#08519C&amp;quot;
    ) +
  geom_point(data = fulton, size = 2) +
  scale_fill_brewer()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-26_market-dem-with-iv/index_files/figure-html/unnamed-chunk-11-1.svg&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The prediction is downward trending as the original curve except with a steeper slope (&lt;code&gt;-0.54&lt;/code&gt; vs &lt;code&gt;-1.09&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;elasticities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Elasticities&lt;/h2&gt;
&lt;p&gt;The paper breaks down the interpretation of the estimated coefficients in terms of elasticities. Given that we have taken the &lt;code&gt;log&lt;/code&gt; of both our quantity and price the coefficients can be interpreted in a clever way. Let’s take a look at why this is the case:&lt;/p&gt;
&lt;p&gt;If we take the log of both &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; of our linear model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\text{log}(y) = \beta_0 + \beta_1\text{log}(x) + \epsilon
\]&lt;/span&gt;
Now solve for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; to find the marginal effects:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y = e^{\beta_o + \beta_1\text{log}(x) + \epsilon}
\]&lt;/span&gt;
Then differentiate with respect to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{dy}{dx} = \frac{\beta_1}{x}e^{\beta_o + \beta_1\text{log}(x) + \epsilon} = \beta_1 \frac{y}{x}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If you then solve for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; you find:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\beta_1 = \frac{dy}{dx} \frac{x}{y}
\]&lt;/span&gt;
So here &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is an elasticity. For a &lt;span class=&#34;math inline&#34;&gt;\(\%\)&lt;/span&gt; increase in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; there is a &lt;span class=&#34;math inline&#34;&gt;\(\beta_1 \%\)&lt;/span&gt; increase in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Elasticities are commonly summarized in a table like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Elasticity&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Elastic&lt;/td&gt;
&lt;td&gt;| &lt;em&gt;E&lt;/em&gt; | &amp;gt; 1&lt;/td&gt;
&lt;td&gt;% change in &lt;em&gt;Q&lt;/em&gt; &amp;gt; % change in &lt;em&gt;P&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Unitary Elastic&lt;/td&gt;
&lt;td&gt;| &lt;em&gt;E&lt;/em&gt; | = 1&lt;/td&gt;
&lt;td&gt;% change in &lt;em&gt;Q&lt;/em&gt; = %change in &lt;em&gt;P&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Inelastic&lt;/td&gt;
&lt;td&gt;| &lt;em&gt;E&lt;/em&gt; | &amp;lt; 1&lt;/td&gt;
&lt;td&gt;% change in &lt;em&gt;Q&lt;/em&gt; &amp;lt; % change in &lt;em&gt;P&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Given the descriptions of elasticity above. We would have two different interpretations of how demand responds to price with the non-IV and the IV estimation. With the non-IV estimation our elasticity coefficient is &lt;code&gt;-0.54&lt;/code&gt; [-0.9, -0.18]. With the IV estimation our elasticity is &lt;code&gt;-1.09&lt;/code&gt; [-2.17, -0.15]. So we would mistakenly interpret the demand elasticity as being inelastic when it actually appears to be unit elastic.&lt;/p&gt;
&lt;p&gt;Some interesting interpretations of this unit elasticity from the paper include:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;First, it is consistent with pricing power on the part of the
fish dealers. A price-setting firm will raise price to the point where the percentage change in the quantity demanded is at least as large as the percentage change in price; otherwise, it would make sense to raise the price even more&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Second, when demand has a unitary elasticity, it means that the percentage change in quantity would always equal the percentage change in price, and the weather would therefore not have much effect on a seller’s revenue, keeping fishermen’s incomes relatively constant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Third, unit elasticities could also result from budget constraints on the part of some buyers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;This was definitely a fun topic to start exploring. I plan on taking a look at &lt;em&gt;difference-in-differences&lt;/em&gt; in the near future as well.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/kTo16ieMCi8&#34;&gt;What’s the Science in Data Science?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aeaweb.org/articles?id=10.1257/jep.20.2.207&#34;&gt;Graddy, Kathryn. 2006. “Markets: The Fulton Fish Market.” Journal of Economic Perspectives, 20 (2): 207-220.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/&#34;&gt;Create supply and demand economics curves with ggplot2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1701.02434&#34;&gt;Michael Betancourt: “A Conceptual Introduction to Hamiltonian Monte Carlo”, 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
