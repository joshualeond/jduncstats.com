[{"authors":["admin"],"categories":null,"content":"Hey, I\u0026rsquo;m Josh Duncan, a former controls engineer that found a passion in data science and statistics. This blog is a platform for extending my data science education. I\u0026rsquo;m currently on a Bayesian modeling journey so you\u0026rsquo;ll likely see posts on learning bayes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"Hey, I\u0026rsquo;m Josh Duncan, a former controls engineer that found a passion in data science and statistics. This blog is a platform for extending my data science education. I\u0026rsquo;m currently on a Bayesian modeling journey so you\u0026rsquo;ll likely see posts on learning bayes.","tags":null,"title":"Josh Duncan","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536469200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536469200,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":1505883600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505883600,"objectID":"acbcc01dc3a816c115c37fa8490d1101","permalink":"/bio/skills/","publishdate":"2017-09-20T00:00:00-05:00","relpermalink":"/bio/skills/","section":"bio","summary":"","tags":null,"title":"Interests","type":"bio"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"31a6136e5e4e2c447aa0413bf3ca952b","permalink":"/bio/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/bio/experience/","section":"bio","summary":"","tags":null,"title":"Work Experience","type":"bio"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.\n  Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906567200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906567200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00-06:00","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":[],"content":" Overview I was listening to the DataFramed podcast where Skipper Seabold was interviewed and spoke about “The Credibility Crisis in Data Science”. He listed a set of techniques that he felt should be more common in the data science community. Some topics he mentioned:\n Instrumental Variables Matching Difference-in-Differences  I’ll be exploring Instrumental Variables using an example of a study on the Fulton Fish Market in NYC:\nThe general idea of the study is to estimate the demand curve for fish at the market. It is unfortunately not as simple as regressing price on demand. There are supply effects that need to be accounted for to isolate the demand effects.\nIn this blog post I’ll be reproducing a portion of this analysis using R, packages of the tidyverse, and the brms package in R.\n Data I discovered data related to this study at the following website: http://people.brandeis.edu/~kgraddy/data.html\nBringing this data into R is very simple. The linked dataset appears to be the cleaned and transformed data used within the paper. Let’s read it into our R environment and take a look:\nlibrary(tidyverse) fulton \u0026lt;- read_tsv(\u0026quot;http://people.brandeis.edu/~kgraddy/datasets/fish.out\u0026quot;) fulton ## # A tibble: 111 x 16 ## day1 day2 day3 day4 date stormy mixed price qty rainy cold ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 0 0 0 911202 1 0 -0.431 8.99 1 0 ## 2 0 1 0 0 911203 1 0 0 7.71 0 0 ## 3 0 0 1 0 911204 0 1 0.0723 8.35 1 1 ## 4 0 0 0 1 911205 1 0 0.247 8.66 0 1 ## 5 0 0 0 0 911206 1 0 0.664 7.84 0 1 ## 6 1 0 0 0 911209 0 0 -0.207 9.30 0 0 ## 7 0 1 0 0 911210 0 1 -0.116 8.92 0 0 ## 8 0 0 1 0 911211 0 0 -0.260 9.11 1 0 ## 9 0 0 0 1 911212 0 1 -0.117 8.31 0 0 ## 10 0 0 0 0 911213 0 0 -0.342 9.21 0 0 ## # … with 101 more rows, and 5 more variables: windspd \u0026lt;dbl\u0026gt;, ## # windspd2 \u0026lt;dbl\u0026gt;, pricelevel \u0026lt;dbl\u0026gt;, totr \u0026lt;dbl\u0026gt;, tots \u0026lt;dbl\u0026gt; Here is a description of the variables we will be using for this work:\n  Variable Units Description    qty log(pounds) The total amount of fish sold on a day  price log($/lb) Average price for the day  day1-day4 dummy var Monday-Thurs  cold dummy var Weather on shore  rainy dummy var Rain on shore  stormy dummy var Wind and waves off shore (a 3-day moving average)    The paper informs the reader that transactions recorded are of a particular fish species called Whiting. We can get a feel for the total amount of Whiting being sold by reproducing Figure 2 from the paper.\n# fixing the date column fulton %\u0026gt;% mutate( date = as.character(date), date = parse_date(date, format = \u0026quot;%y%m%d\u0026quot;) ) %\u0026gt;% ggplot(aes(x = date, y = exp(qty))) + geom_col() + labs( title = \u0026quot;Figure 2\u0026quot;, subtitle = \u0026quot;Daily Volumes of Whiting\u0026quot;, x = \u0026quot;Date (December 2, 1991-May 8, 1992)\u0026quot;, y = \u0026quot;Quantity (pounds)\u0026quot; ) Reproducing this figure gave me confidence that I had the correct data to reproduce the analysis.\n Demand Curve The naive way in attempting to find the relationship between price and demand (the demand curve) would be to regress quantity on price:\nggplot(fulton, aes(x = price, y = qty)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) But would this be the demand curve? It actually wouldn’t be. According to intro economics, each one of the points in the plot is the intersection of both a supply and demand curve. Something like this:\nSo how does the author go about estimating the demand curve? How do you isolate the demand effects from the supply? Well, it’s in the title of this post. We’ll be using Instrumental Variables (or IV).\n Regressions The paper includes a table of estimated coefficients like so:\nI’ll be reproducing this table but with Bayesian estimation methods.\nOLS (Ordinary Least Squares) Reproduced First, let’s perform the linear regression without IV. We can use the brm function as a drop in replacement of lm to get distributions of our parameter estimates. Here the brms package is performing a Bayesian estimation using MCMC. I’m keeping the default “uninformative” priors set by the package.\nStarting with column 1 of table 2 we estimate the coefficients with only qty and price:\nlibrary(brms) library(tidybayes) library(ggridges) # column 1 in table 2 fit1 \u0026lt;- brm(qty ~ price, data = fulton, refresh = 0) fit1 %\u0026gt;% posterior_samples() %\u0026gt;% ggplot(aes(x = b_price)) + geom_density_line() The brms package provides an abstraction layer to the Stan probabilistic programming language. So if you’re curious what these “uninformative” priors that I breezed over actually are, take a look at the generated code with the stancode function. Here is an excerpt of the stan code generated for the model above:\nmodel { vector[N] mu = temp_Intercept + Xc * b; // priors including all constants target += student_t_lpdf(temp_Intercept | 3, 9, 10); target += student_t_lpdf(sigma | 3, 0, 10) - 1 * student_t_lccdf(0 | 3, 0, 10); // likelihood including all constants if (!prior_only) { target += normal_lpdf(Y | mu, sigma); } } Moving to column 2 of table 2 we estimate the model including the dummy day variables, cold, and rainy variables:\n# column 2 in table 2 fit1_full \u0026lt;- brm( qty ~ price + day1 + day2 + day3 + day4 + cold + rainy, data = fulton, refresh = 0 ) # a plot of parameter estimates fit1_full %\u0026gt;% posterior_samples() %\u0026gt;% gather(b_price:b_rainy, key = \u0026quot;coef\u0026quot;, value = \u0026quot;est\u0026quot;) %\u0026gt;% ggplot(aes(x = est, y = coef)) + geom_density_ridges() We can see that the estimated coefficient for price in this context is the same for both the simple linear regression and the regression accounting for weekday and onshore weather.\n IV Reproduced Before performing the estimation I wanted to add a quote from the paper. I thought Kathryn Graddy explained the IV estimation well:\n That is, first a regression is run with log price as the dependent variable and the storminess of the weather as the explanatory variable. This regression seeks to measure the variation in price that is attributable to stormy weather. The coefficients from this regression are then used to predict log price on each day, and these predicted values for price are inserted back into the regression.\n Now let’s move on to using IV. This is possible with the brms package and its ability to specify multivariate models. We’ll piece it together with two separate formulas defined in the bf function calls below.\nThe first estimation will be for column 3 of table 2:\n# measure variation in price attributable to stormy weather fit2a \u0026lt;- bf(price ~ stormy) # estimate demand fit2b \u0026lt;- bf(qty ~ price) # column 3 in table 2 fit2 \u0026lt;- brm(fit2a + fit2b, data = fulton, refresh = 0) fit2 %\u0026gt;% posterior_samples() %\u0026gt;% ggplot(aes(x = b_qty_price)) + geom_density_line() And lastly we’ll estimate the IV with the remaining variables (column 4):\n# add additional demand specific variables fit2b_full \u0026lt;- bf(qty ~ price + day1 + day2 + day3 + day4 + cold + rainy) # column 4 in table 2 fit2_full \u0026lt;- brm(fit2a + fit2b_full, data = fulton, refresh = 0) fit2_full %\u0026gt;% posterior_samples() %\u0026gt;% gather(b_qty_price:b_qty_rainy, key = \u0026quot;coef\u0026quot;, value = \u0026quot;est\u0026quot;) %\u0026gt;% ggplot(aes(x = est, y = coef)) + geom_density_ridges()  Visualizing the Demand Curve Now we can plot the demand curve with isolated demand effects. I’ll use the first IV estimation with only qty, price, and stormy variables:\nfulton %\u0026gt;% add_predicted_draws(fit2) %\u0026gt;% filter(.category == \u0026quot;qty\u0026quot;) %\u0026gt;% ggplot(aes(x = price, y = qty)) + stat_lineribbon( aes(y = .prediction), .width = c(.99, .95, .8, .5), color = \u0026quot;#08519C\u0026quot; ) + geom_point(data = fulton, size = 2) + scale_fill_brewer() The prediction is downward trending as the original curve except with a steeper slope (-0.54 vs -1.09).\n  Elasticities The paper breaks down the interpretation of the estimated coefficients in terms of elasticities. Given that we have taken the log of both our quantity and price the coefficients can be interpreted in a clever way. Let’s take a look at why this is the case:\nIf we take the log of both \\(y\\) and \\(x\\):\n\\[ \\text{log}(y) = \\beta_0 + \\beta_1\\text{log}(x) + \\epsilon \\] Now solve for \\(y\\) to find the marginal effects:\n\\[ y = e^{\\beta_o + \\beta_1\\text{log}(x) + \\epsilon} \\] Then differentiate with respect to \\(x\\):\n\\[ \\frac{dy}{dx} = \\frac{\\beta_1}{x}e^{\\beta_o + \\beta_1\\text{log}(x) + \\epsilon} = \\beta_1 \\frac{y}{x} \\]\nIf you then solve for \\(\\beta_1\\) you find:\n\\[ \\beta_1 = \\frac{dy}{dx} \\frac{x}{y} \\] So here \\(\\beta_1\\) is an elasticity. For a unit increase in \\(x\\) there is a \\(\\beta_1 \\%\\) increase in \\(y\\).\nElasticities are commonly summarized in a table like this:\n  Elasticity Value Description    Elastic | E | \u0026gt; 1 % change in Q \u0026gt; % change in P  Unitary Elastic | E | = 1 % change in Q = %change in P  Inelastic | E | \u0026lt; 1 % change in Q \u0026lt; % change in P    Given the descriptions of elasticity above. We would have two different interpretations of how demand responds to price with the non-IV and the IV estimation. With the non-IV estimation our elasticity coefficient is -0.54 [-0.89, -0.18]. With the IV estimation our elasticity is -1.09 [-2.17, -0.17]. So we would mistakenly interpret the demand elasticity as being inelastic when it actually appears to be unitary elastic.\nSome interesting interpretations of this unit elasticity from the paper include:\n First, it is consistent with pricing power on the part of the fish dealers. A price-setting firm will raise price to the point where the percentage change in the quantity demanded is at least as large as the percentage change in price; otherwise, it would make sense to raise the price even more\n  Second, when demand has a unitary elasticity, it means that the percentage change in quantity would always equal the percentage change in price, and the weather would therefore not have much effect on a seller’s revenue, keeping fishermen’s incomes relatively constant.\n  Third, unit elasticities could also result from budget constraints on the part of some buyers.\n  Wrapping Up This was definitely a fun topic to begin exploring. I plan on taking a look at difference-in-differences in the near future as well.\n References  DataFramed: The Credibility Crisis in Data Science Graddy, Kathryn. 2006. “Markets: The Fulton Fish Market.” Journal of Economic Perspectives, 20 (2): 207-220. Create supply and demand economics curves with ggplot2 Log-level and Log-log transformations in Linear Regression Models   ","date":1553558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553558400,"objectID":"b73959769b76a27d5f02b5c40be9d32a","permalink":"/post/market-demand-with-instrumental-variables/","publishdate":"2019-03-26T00:00:00Z","relpermalink":"/post/market-demand-with-instrumental-variables/","section":"post","summary":"Overview I was listening to the DataFramed podcast where Skipper Seabold was interviewed and spoke about “The Credibility Crisis in Data Science”. He listed a set of techniques that he felt should be more common in the data science community. Some topics he mentioned:\n Instrumental Variables Matching Difference-in-Differences  I’ll be exploring Instrumental Variables using an example of a study on the Fulton Fish Market in NYC:\nThe general idea of the study is to estimate the demand curve for fish at the market.","tags":["rstats","econometrics","bayes"],"title":"Market Demand with Instrumental Variables","type":"post"},{"authors":null,"categories":null,"content":" Motivation Why am I writing about KDE\u0026rsquo;s? At the recommendation of Will Kurt\u0026rsquo;s probability blog I\u0026rsquo;ve been reading a great book on data analysis by Philipp K. Janert:\nThis book has a great intro to KDEs that explain the motivation. My own abbreviated version are that KDEs provide a useful technique to visualize a variables distribution. Visualizing your data is an important step to take early in the data analysis stage. In fact, there are many metrics that we commonly use to understand a variable that have an implicit assumption that your data are unimodal (having a single peak). If your data doesn\u0026rsquo;t have this structure then you may be mislead by measures of central tendency (mean/median/mode), outliers, or other statistical methods (linear regression, t-tests, etc.).\nThis post\u0026rsquo;s structure follows closely with how I commonly learn topics. I start at a high level, using a pre-canned solution for the algorithm, and then work backward to find out what\u0026rsquo;s going on underneath.\nI use a small example I discovered on the Wikipedia page for KDEs. It uses a handful of data points for a single variable:\n   Sample Value     1 -2.1   2 -1.3   3 -0.4   4 1.9   5 5.1   6 6.2    Let\u0026rsquo;s start with a basic dot plot of these points. I\u0026rsquo;ll be using the Julia Programming Language for these examples.\nusing StatsPlots # initialize an array of the samples x = [-2.1; -1.3; -0.4; 1.9; 5.1; 6.2]; # plot it out scatter(x, zeros(length(x)), legend = false)  KDE with KernelDensity.jl Now applying the quick and easy solution: a package. This package has a function named kde that takes a one dimensional array (or vector), a bandwidth argument, and a chosen kernel (we\u0026rsquo;ll use the default). So let\u0026rsquo;s see it:\nimport KernelDensity KernelDensity.kde(x, bandwidth = sqrt(2.25)) |\u0026gt; x -\u0026gt; plot!(x, legend = false)  There we go, we\u0026rsquo;ve applied KDE to these data points and we can now see the bimodal nature of this data. If all we wanted to do was visualize the distribution then we\u0026rsquo;re done. I\u0026rsquo;d like to dig a bit deeper though.\nKDE with Distributions.jl What is the kernel part of this about? What was the default kernel we used in the previous section? The kde function from the package used a default kernel associated with the Normal distribution. But to understand what this all means we need to take a look at the definition of Kernel Density Estimation:\n$$ D_h(x; {x_i}) = \\sum_{i=1}^n \\frac{1}{nh} K\\left(\\frac{x - x_i}{h}\\right) $$\nBreaking down this formula a bit: The kernel is the function shown above as $K$ and Janert describes it like so:\n To form a KDE, we place a kernel —that is, a smooth, strongly peaked function—at the position of each data point. We then add up the contributions from all kernels to obtain a smooth curve, which we can evaluate at any point along the x axis\n We are effectively calculating weighted distances from our data points to points along the x axis. There is a great interactive introduction to kernel density estimation here. I highly recommend it because you can play with bandwidth, select different kernel methods, and check out the resulting effects.\nAs I mentioned before, the default kernel for this package is the Normal (or Gaussian) probability density function (pdf):\n$$ K(x) = \\frac{1}{\\sqrt{2\\pi}}\\text{exp}\\left(-\\frac{1}{2}x^2\\right) $$\nSince we are calculating pdfs I\u0026rsquo;ll use the Distributions.jl package to create each distribution, calculate the densities, and sum the results.\nusing Distributions dists = Normal.(x, sqrt(2.25))  6-element Array{Distributions.Normal{Float64},1}: Distributions.Normal{Float64}(μ=-2.1, σ=1.5) Distributions.Normal{Float64}(μ=-1.3, σ=1.5) Distributions.Normal{Float64}(μ=-0.4, σ=1.5) Distributions.Normal{Float64}(μ=1.9, σ=1.5) Distributions.Normal{Float64}(μ=5.1, σ=1.5) Distributions.Normal{Float64}(μ=6.2, σ=1.5)  Here we see a neat feature of the Julia language. Any Julia function can be vectorized (or broadcasted) by the application of the . (or \u0026ldquo;dot\u0026rdquo;) operator. See this blog post if you want to learn more about it. Above we applied the Normal method element-wise creating an array of Normal distributions. The mean of our individual distributions being our data points and a variance of 2.25 (aka our chosen bandwidth). Let\u0026rsquo;s plot each of these distributions:\nplot(dists, legend = false)  Summing up their probability densities across all of x.\n# create an iterator x_d = range(-7, 11, length = 100) # find the kde with a gaussian kernel dens = sum(pdf.(eachdist, x_d) for eachdist in dists) plot!(x_d, dens)  The resulting shape of the KDE is identical to the one we first calculated. We could stop here except this is really just a special case where we are using the gaussian kernel. Let\u0026rsquo;s extrapolate a bit so we could use different kernels.\nKernel Density from Scratch To apply a new kernel method we can just write the KDE code from scratch. Below I\u0026rsquo;ve defined the KDE function as D and the kernel argument as K to mimic the math above.\n# define some kernels: # gaussian kernel kgauss(x) = 1/sqrt(2π) * exp(-1/2 * x^2) # boxcar kbox(x) = abs(x) \u0026lt;= 1 ? 1/2 : 0 # triangular ktri(x) = abs(x) \u0026lt;= 1 ? 1 - abs(x) : 0 # define the KDE function D(x, h, xi, K) = 1/(length(xi) * h) * sum(K.((x .- xi) / h)) # evaluate KDE along the x-axis using comprehensions dens = [D(xstep, sqrt(2.25), x, K) for xstep in x_d, K in (kgauss, kbox, ktri)] # visualize the kernels plot(x_d, dens, label = [\u0026quot;Gaussian\u0026quot;, \u0026quot;Box\u0026quot;, \u0026quot;Triangular\u0026quot;])  In my example above I used some shorthand Julia syntax. The ?: syntax is called a ternary operator and makes a conditional if-else statement more compact. I also used Julia\u0026rsquo;s Assignment form for my function definitions above because it looks a lot more like the math involved. You could have easily defined each of these functions to look more like so:\nfunction foo(x) if ... ... else ... end return ... end  What\u0026rsquo;s next? A short post on cumulative distribution functions (cdf) using Julia will likely follow this one. Janert introduces both kdes and cdfs in his chapter A Single Variable: Shape and Distribution and they complement each other really well. Thanks for reading!\n","date":1552712400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552712400,"objectID":"b74e75123768706f2f14b4ac8374c7e6","permalink":"/post/2019-03-16_kde-scratch/","publishdate":"2019-03-16T00:00:00-05:00","relpermalink":"/post/2019-03-16_kde-scratch/","section":"post","summary":"Motivation Why am I writing about KDE\u0026rsquo;s? At the recommendation of Will Kurt\u0026rsquo;s probability blog I\u0026rsquo;ve been reading a great book on data analysis by Philipp K. Janert:\nThis book has a great intro to KDEs that explain the motivation. My own abbreviated version are that KDEs provide a useful technique to visualize a variables distribution. Visualizing your data is an important step to take early in the data analysis stage.","tags":["julia","datasci"],"title":"Kernel Density Estimation from Scratch","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536469200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536469200,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"/tutorial/example/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441083600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441083600,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"/publication/person-re-id/","publishdate":"2015-09-01T00:00:00-05:00","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372654800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372654800,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"/publication/clothing-search/","publishdate":"2013-07-01T00:00:00-05:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"A mobile visual clothing search system is presented whereby a smart phone user can either choose a social networking image or capture a new photo of a person wearing clothing of interest and search for similar clothing in a large cloud-based ecommerce database. The phone's GPS location is used to re-rank results by retail store location, to inform the user of local stores where similar clothing items can be tried on.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]