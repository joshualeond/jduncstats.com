[{"authors":["admin"],"categories":null,"content":"Hey there, I\u0026rsquo;m Josh Duncan, a former controls engineer that found a passion in data science and statistics.\nStatistical modeling and uncertainty fascinate me. I\u0026rsquo;m currently on a Bayesian modeling journey so you\u0026rsquo;ll likely see posts on learning bayes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://jduncstats.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"Hey there, I\u0026rsquo;m Josh Duncan, a former controls engineer that found a passion in data science and statistics.\nStatistical modeling and uncertainty fascinate me. I\u0026rsquo;m currently on a Bayesian modeling journey so you\u0026rsquo;ll likely see posts on learning bayes.","tags":null,"title":"Josh Duncan","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536469200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536469200,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://jduncstats.com/tutorial/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":1505883600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505883600,"objectID":"acbcc01dc3a816c115c37fa8490d1101","permalink":"https://jduncstats.com/bio/skills/","publishdate":"2017-09-20T00:00:00-05:00","relpermalink":"/bio/skills/","section":"bio","summary":"","tags":null,"title":"Interests","type":"bio"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"31a6136e5e4e2c447aa0413bf3ca952b","permalink":"https://jduncstats.com/bio/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/bio/experience/","section":"bio","summary":"","tags":null,"title":"Work Experience","type":"bio"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.\n  Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using url_slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906567200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906567200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://jduncstats.com/talk/example/","publishdate":"2017-01-01T00:00:00-06:00","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":" Hard Problems 4H1. The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.\nlibrary(tidyverse) library(knitr) library(kableExtra) kung \u0026lt;- tibble::tribble( ~individual, ~weight, 1, 46.95, 2, 43.72, 3, 64.78, 4, 32.59, 5, 54.63 ) # kable(kung, digits = 3, row.names = FALSE, align = \u0026quot;c\u0026quot;, caption = NULL) %\u0026gt;% # kable_styling(bootstrap_options = \u0026quot;striped\u0026quot;, full_width = FALSE) Well it looks like first we need to estimate this model. In the book on page 96 we see the MAP estimation of this model on the filtered dataset. I’m going to fit this one for predictions.\nlibrary(rethinking) data(\u0026quot;Howell1\u0026quot;) d \u0026lt;- Howell1 d2 \u0026lt;- d[d$age \u0026gt;= 18, ] # fit model m4.3 \u0026lt;- rethinking::map( alist( height ~ dnorm(mu, sigma), # likelihood mu \u0026lt;- a + b * weight, # linear model a ~ dnorm(156, 100), # prior b ~ dnorm(0, 10), # prior sigma ~ dunif(0, 50) # prior ), data = d2 ) Now the model is fit and we can estimate the predictions in two ways:\nCollect posterior samples of the parameters of the estimated model and for each weight in the above dataframe sample from a Normal distribution with our posterior samples as parameters Use the convenience function in the rethinking package called sim() to do the above giving it only the new weights  post \u0026lt;- extract.samples(m4.3) head(post) ## a b sigma ## 1 112.2954 0.9491699 5.000737 ## 2 113.0658 0.9153298 4.843345 ## 3 113.0045 0.9264236 5.104805 ## 4 109.1693 0.9956567 5.036712 ## 5 110.9276 0.9727692 4.944080 ## 6 113.6316 0.9208830 5.085948 sim.height \u0026lt;- sapply(kung$weight, function(weight) rnorm( n = nrow(post), mean = post$a + post$b * weight, sd = post$sigma ) ) (sim.PI \u0026lt;- apply(sim.height, 2, PI, prob = 0.89)) ## [,1] [,2] [,3] [,4] [,5] ## 5% 148.1800 145.1733 164.2963 135.4308 155.3258 ## 94% 164.4171 161.4956 180.7816 151.6542 171.5112 And the convenient way:\nsim.height \u0026lt;- sim(m4.3, data = list(weight = kung$weight)) ## [ 100 / 1000 ] [ 200 / 1000 ] [ 300 / 1000 ] [ 400 / 1000 ] [ 500 / 1000 ] [ 600 / 1000 ] [ 700 / 1000 ] [ 800 / 1000 ] [ 900 / 1000 ] [ 1000 / 1000 ] (sim.PI \u0026lt;- apply(sim.height, 2, PI, prob = 0.89)) ## [,1] [,2] [,3] [,4] [,5] ## 5% 147.7267 145.3358 164.4972 135.5728 155.2548 ## 94% 164.1712 161.6233 180.5642 151.1673 171.6732 We have relatively the same results here which is expected. Let’s get the mean values as well:\nsim.mean \u0026lt;- apply(sim.height, 2, mean) Now let’s put all of this in the dataframe:\nkung$exp_height \u0026lt;- sim.mean kung$lo_89 \u0026lt;- sim.PI[1,] kung$hi_89 \u0026lt;- sim.PI[2,] # kable(kung, digits = 3, row.names = FALSE, align = \u0026quot;c\u0026quot;, caption = NULL) %\u0026gt;% # kable_styling(bootstrap_options = \u0026quot;striped\u0026quot;, full_width = FALSE)   4H2. Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right you should end up with a new data frame with 192 rows in it.\nd3 \u0026lt;- d[d$age \u0026lt; 18,] (a)  Fit a linear regression to these data, using map. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets?\n fit \u0026lt;- rethinking::map( alist( height ~ dnorm(mu, sigma), # likelihood mu \u0026lt;- a + b * weight, # linear model a ~ dnorm(156, 100), # prior b ~ dnorm(0, 10), # prior sigma ~ dunif(0, 50) # prior ), data = d3 ) Let’s look at the results of this model:\npost_early \u0026lt;- extract.samples(fit) precis(post_early) ## Mean StdDev |0.89 0.89| ## a 58.26 1.38 55.97 60.35 ## b 2.72 0.07 2.61 2.82 ## sigma 8.44 0.43 7.77 9.13 So we see for every 1 unit increase in weight a child should be 2.72 cm taller. Or as the question has asked 10 unit increase is a 27.2 cm increase in height. For every 22 lb increase there is a corresponding ~1 foot increase in height.\n (b)  Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for predicted heights.\n plot(height ~ weight, d3, col = col.alpha(rangi2, 0.5)) # get index for calculations weight.seq \u0026lt;- seq(0, 50, by = 1) # extract samples of parameters and calculate expected mu mu \u0026lt;- link(fit, data = data.frame(weight = weight.seq)) ## [ 100 / 1000 ] [ 200 / 1000 ] [ 300 / 1000 ] [ 400 / 1000 ] [ 500 / 1000 ] [ 600 / 1000 ] [ 700 / 1000 ] [ 800 / 1000 ] [ 900 / 1000 ] [ 1000 / 1000 ] mu.mean \u0026lt;- apply(mu, 2, mean) lines(weight.seq, mu.mean) mu.HPDI \u0026lt;- apply(mu, 2, HPDI) shade(mu.HPDI, weight.seq) # simulate posterior observations of the model fit sim.height \u0026lt;- sim(fit, data = data.frame(weight = weight.seq)) ## [ 100 / 1000 ] [ 200 / 1000 ] [ 300 / 1000 ] [ 400 / 1000 ] [ 500 / 1000 ] [ 600 / 1000 ] [ 700 / 1000 ] [ 800 / 1000 ] [ 900 / 1000 ] [ 1000 / 1000 ] height.HPDI \u0026lt;- apply(sim.height, 2, HPDI) shade(height.HPDI, weight.seq)  (c)  What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.\n Well the model appears to be doing good job with the data at hand. The prior’s were set for persons age \u0026gt; 18 so these should be adjusted. Something of conrern is that you see a non-linear structure in this data. So the two tails of the data are not covered well by the model. This non-linearity could be accounted for with a polynomial regression or with splines.\n  4H3. Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.\n(a)  Model the relationship between height(cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation:\n \\[ \\begin{aligned} h_i \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\ \\mu_i = \\alpha + \\beta \\text{log}(w_i) \\\\ \\alpha \\sim \\text{Normal}(178, 100) \\\\ \\beta \\sim \\text{Normal}(0, 100) \\\\ \\sigma \\sim \\text{Uniform}(0, 50) \\end{aligned} \\] where \\(h_i\\) is the height of individual \\(i\\) and \\(w_i\\) is the weight (in kg) of individual \\(i\\). The function for computing a natural log in R is just log. Can you interpret the resulting estimates?\nfit_all \u0026lt;- rethinking::map( alist( height ~ dnorm(mu, sigma), mu \u0026lt;- a + b * log(weight), # linear model a ~ dnorm(178, 100), b ~ dnorm(0, 100), sigma ~ dunif(0, 50) ), data = d ) Now the model is fit let’s review the coefficients.\nprecis(fit_all) ## Mean StdDev 5.5% 94.5% ## a -23.78 1.34 -25.92 -21.65 ## b 47.08 0.38 46.46 47.69 ## sigma 5.13 0.16 4.89 5.38 plot(precis(fit_all)) When the weight is low or equivalent to 1 then the height would be -23 which is not insightful. Given that this is a log-level model we can interpret our \\(\\beta\\) as a one percent increase in weight corresponds to a \\(\\beta/100 = 47.08/100\\) unit increase in height.\n (b) Begin with this plot:\nplot(height ~ weight, data = d, col = col.alpha(rangi2, 0.4)) Then use the samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and (3) the 97% HPDI for predicted heights.\nweight.seq \u0026lt;- seq(2, 65, by = 1) all_samp \u0026lt;- link(fit_all, data = data.frame(weight = weight.seq)) ## [ 100 / 1000 ] [ 200 / 1000 ] [ 300 / 1000 ] [ 400 / 1000 ] [ 500 / 1000 ] [ 600 / 1000 ] [ 700 / 1000 ] [ 800 / 1000 ] [ 900 / 1000 ] [ 1000 / 1000 ] all_mu \u0026lt;- apply(all_samp, 2, mean) all_mu.HPDI \u0026lt;- apply(all_samp, 2, HPDI, prob = 0.97) all_sim \u0026lt;- sim(fit_all, data = data.frame(weight = weight.seq)) ## [ 100 / 1000 ] [ 200 / 1000 ] [ 300 / 1000 ] [ 400 / 1000 ] [ 500 / 1000 ] [ 600 / 1000 ] [ 700 / 1000 ] [ 800 / 1000 ] [ 900 / 1000 ] [ 1000 / 1000 ] all_sim.HPDI \u0026lt;- apply(all_sim, 2, HPDI, prob = 0.97) plot(height ~ weight, data = d, col = col.alpha(rangi2, 0.4)) # the predicted mean height lines(weight.seq, all_mu) # the 97% HPDI of the mean shade(all_mu.HPDI, weight.seq) # the 97% HPDI for predictions shade(all_sim.HPDI, weight.seq)   ","date":1552270394,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552270394,"objectID":"da743bec7bb56ad1c8927f2d98829e71","permalink":"https://jduncstats.com/post/hw2-ch-4/","publishdate":"2019-03-10T21:13:14-05:00","relpermalink":"/post/hw2-ch-4/","section":"post","summary":"Hard Problems 4H1. The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.\nlibrary(tidyverse) library(knitr) library(kableExtra) kung \u0026lt;- tibble::tribble( ~individual, ~weight, 1, 46.95, 2, 43.72, 3, 64.78, 4, 32.59, 5, 54.63 ) # kable(kung, digits = 3, row.","tags":["rstats","bayes"],"title":"Homework 2, Chapter 4","type":"post"},{"authors":null,"categories":null,"content":" KDE with KernelDensity.jl From the Kernel Density Estimation Wikipedia site we can take a look at reproducing the Example section.\nusing StatsPlots x = [-2.1; -1.3; -0.4; 1.9; 5.1; 6.2]; scatter(x, zeros(length(x)), legend = false)  Now applying the quick and easy solution: a package.\nimport KernelDensity KernelDensity.kde(x, bandwidth = sqrt(2.25)) |\u0026gt; x -\u0026gt; plot!(x, legend = false)  KDE with Distributions.jl Creating individual distributions for each data point.\nusing Distributions dists = Normal.(x, sqrt(2.25))  6-element Array{Distributions.Normal{Float64},1}: Distributions.Normal{Float64}(μ=-2.1, σ=1.5) Distributions.Normal{Float64}(μ=-1.3, σ=1.5) Distributions.Normal{Float64}(μ=-0.4, σ=1.5) Distributions.Normal{Float64}(μ=1.9, σ=1.5) Distributions.Normal{Float64}(μ=5.1, σ=1.5) Distributions.Normal{Float64}(μ=6.2, σ=1.5)  The Normal function above is vectorized by the use of the . operator. This creates an array of Normal distributions. Let\u0026rsquo;s plot each of these distributions:\nplot(dists, legend = false)  Summing up their probability densities across all of x.\nx_d = range(-7, 11, length = 100) dens = sum(pdf.(eachdist, x_d) for eachdist in dists) plot!(x_d, dens)  Interject a little math:\n$$ \\hat f_h(x) = \\frac{1}{n} \\sum_{i=1}^n K_h(x - x_i) $$\nKernel Density from Scratch kde(z, ω, xv) = sum(@. exp(-0.5 * ((z - xv) / ω)^2) / sqrt(2π*ω^2)) / length(xv) dens = [] for x_d in range(-7, 10, length = 100) push!(dens, kde(x_d, sqrt(2.25), x)) end plot(dens, legend = false)  ","date":1552011194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552011194,"objectID":"be92b5f11f8a240ddded101a4d9f507d","permalink":"https://jduncstats.com/post/2019-3-7-kde-scratch/","publishdate":"2019-03-07T21:13:14-05:00","relpermalink":"/post/2019-3-7-kde-scratch/","section":"post","summary":"KDE with KernelDensity.jl From the Kernel Density Estimation Wikipedia site we can take a look at reproducing the Example section.\nusing StatsPlots x = [-2.1; -1.3; -0.4; 1.9; 5.1; 6.2]; scatter(x, zeros(length(x)), legend = false)  Now applying the quick and easy solution: a package.\nimport KernelDensity KernelDensity.kde(x, bandwidth = sqrt(2.25)) |\u0026gt; x -\u0026gt; plot!(x, legend = false)  KDE with Distributions.jl Creating individual distributions for each data point.","tags":["julia"],"title":"Kernel Density Estimation from Scratch","type":"post"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536469200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536469200,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://jduncstats.com/tutorial/example/","publishdate":"2018-09-09T00:00:00-05:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["GA Cushen"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1441083600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441083600,"objectID":"d77fa4a74076ffcd7ca6c21cfc27a4b2","permalink":"https://jduncstats.com/publication/person-re-id/","publishdate":"2015-09-01T00:00:00-05:00","relpermalink":"/publication/person-re-id/","section":"publication","summary":"Person re-identification is a critical security task for recognizing a person across spatially disjoint sensors. Previous work can be computationally intensive and is mainly based on low-level cues extracted from RGB data and implemented on a PC for a fixed sensor network (such as traditional CCTV). We present a practical and efficient framework for mobile devices (such as smart phones and robots) where high-level semantic soft biometrics are extracted from RGB and depth data. By combining these cues, our approach attempts to provide robustness to noise, illumination, and minor variations in clothing. This mobile approach may be particularly useful for the identification of persons in areas ill-served by fixed sensors or for tasks where the sensor position and direction need to dynamically adapt to a target. Results on the BIWI dataset are preliminary but encouraging. Further evaluation and demonstration of the system will be available on our website.","tags":[],"title":"A Person Re-Identification System For Mobile Devices","type":"publication"},{"authors":["GA Cushen","MS Nixon"],"categories":null,"content":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.\n","date":1372654800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372654800,"objectID":"2b4d919e3cf73dfcd0063c88fe01cb00","permalink":"https://jduncstats.com/publication/clothing-search/","publishdate":"2013-07-01T00:00:00-05:00","relpermalink":"/publication/clothing-search/","section":"publication","summary":"A mobile visual clothing search system is presented whereby a smart phone user can either choose a social networking image or capture a new photo of a person wearing clothing of interest and search for similar clothing in a large cloud-based ecommerce database. The phone's GPS location is used to re-rank results by retail store location, to inform the user of local stores where similar clothing items can be tried on.","tags":[],"title":"Mobile visual clothing search","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://jduncstats.com/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]