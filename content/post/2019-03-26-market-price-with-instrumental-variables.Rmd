---
title: Market Demand with Instrumental Variables
author: J. Duncan
date: '2019-03-26'
draft: false
slug: market-demand-with-instrumental-variables
categories: []
tags:
  - rstats
  - econometrics
  - bayes
image:
  caption: ''
  focal_point: ''
output:
  blogdown::html_page:
    dev: "svg"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Overview

I was listening to the [DataFramed](https://www.datacamp.com/community/podcast/credibility-crisis-in-data-science) podcast where Skipper Seabold was interviewed and spoke about "The Credibility Crisis in Data Science". He listed a set of techniques that he felt should be more common in the data science community. Some topics he mentioned:

* Instrumental Variables
* Matching
* Difference-in-Differences

I'll be exploring *Instrumental Variables* using an example of a [study](https://www.aeaweb.org/articles?id=10.1257/jep.20.2.207) on the **Fulton Fish Market** in NYC:

<img src="/post/2019-03-26-market-price-with-instrumental-variables_files/fulton.jpg" alt="drawing" width="50%"/>

The general idea of the study is to estimate the demand curve for fish at the market. It is unfortunately not as simple as regressing price on demand. There are supply effects that need to be accounted for to isolate the demand effects.

In this blog post I'll be reproducing a portion of this analysis using R, packages of the [tidyverse](https://www.tidyverse.org/), and the [brms](https://github.com/paul-buerkner/brms) package in R.

## Data

I discovered data related to this study at the following website:
http://people.brandeis.edu/~kgraddy/data.html

Bringing this data into R is very simple. The linked dataset appears to be the cleaned and transformed data used within the paper. Let's read it into our R environment and take a look:

```{r}
library(tidyverse)

fulton <- read_tsv("http://people.brandeis.edu/~kgraddy/datasets/fish.out")
fulton
```

Here is a description of the variables we will be using for this work:

Variable | Units | Description
------ | ----- | -----
 qty   | log(pounds) | The total amount of fish sold on a day
 price | log($/lb) | Average price for the day
 day1-day4 | dummy var | Monday-Thurs
 cold | dummy var | Weather on shore
 rainy | dummy var | Rain on shore
 stormy | dummy var | Wind and waves off shore (a 3-day moving average)
 
The paper informs the reader that transactions recorded are of a particular fish species called Whiting. We can get a feel for the total amount of Whiting being sold by reproducing Figure `2` from the paper.

```{r}
# fixing the date column 
fulton %>% 
  mutate(
    date = as.character(date),
    date = parse_date(date, format = "%y%m%d")
  ) %>% 
  ggplot(aes(x = date, y = exp(qty))) +
    geom_col() +
    labs(
      title = "Figure 2",
      subtitle = "Daily Volumes of Whiting",
      x = "Date (December 2, 1991-May 8, 1992)",
      y = "Quantity (pounds)"
      )
```

Reproducing this figure gave me confidence that I had the correct data to reproduce the analysis.

## Demand Curve

The naive way in attempting to find the relationship between price and demand (the demand curve) would be to regress quantity on price:

```{r}
ggplot(fulton, aes(x = price, y = qty)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

But would this be the demand curve? It actually wouldn't be. According to intro economics, each one of the points in the plot is the intersection of both a supply and demand curve. Something like [this](https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/):

<img src="/post/2019-03-26-market-price-with-instrumental-variables_files/supply-demand-intersection-simple-1.png" alt="drawing" width="80%"/>

So how does the author go about estimating the demand curve? How do you isolate the demand effects from the supply? Well, it's in the title of this post. We'll be using **Instrumental Variables** (or IV). 

## Regressions

The paper includes a table of estimated coefficients like so:

<img src="/post/2019-03-26-market-price-with-instrumental-variables_files/table-2.png" alt="drawing" width="80%"/>

I'll be reproducing this table but with Bayesian estimation methods.

### OLS (Ordinary Least Squares) Reproduced
First, let's perform the linear regression without IV. We can use the `brm` function as a drop in replacement of `lm` to get distributions of our parameter estimates. Here the `brms` package is performing a Bayesian estimation using MCMC. I'm keeping the default "uninformative" priors set by the package.

Starting with column `1` of table `2` we estimate the coefficients with only `qty` and `price`:

```{r}
library(brms)
library(tidybayes)
library(ggridges)

# column 1 in table 2
fit1 <- brm(qty ~ price, data = fulton, refresh = 0)

fit1 %>% 
  posterior_samples() %>% 
  ggplot(aes(x = b_price)) +
    geom_density_line()
```

The `brms` package provides an abstraction layer to the `Stan` probabilistic programming language. So if you're curious what these "uninformative" priors that I breezed over actually are, take a look at the generated code with the `stancode` function. Here is an excerpt of the stan code generated for the model above:

```{stan, output.var="ex1", eval = FALSE}
model {
  vector[N] mu = temp_Intercept + Xc * b;
  // priors including all constants
  target += student_t_lpdf(temp_Intercept | 3, 9, 10);
  target += student_t_lpdf(sigma | 3, 0, 10)
    - 1 * student_t_lccdf(0 | 3, 0, 10);
  // likelihood including all constants
  if (!prior_only) {
    target += normal_lpdf(Y | mu, sigma);
  }
}
```

Moving to column `2` of table `2` we estimate the model including the dummy `day` variables, `cold`, and `rainy` variables:

```{r}
# column 2 in table 2
fit1_full <- brm(
  qty ~ price + day1 + day2 + day3 + day4 + cold + rainy,
  data = fulton,
  refresh = 0
)

# a plot of parameter estimates
fit1_full %>% 
  posterior_samples() %>% 
  gather(b_price:b_rainy, key = "coef", value = "est") %>% 
  ggplot(aes(x = est, y = coef)) +
    geom_density_ridges()
```

We can see that the estimated coefficient for price in this context is the same for both the simple linear regression and the regression accounting for weekday and onshore weather. 

### IV Reproduced

Before performing the estimation I wanted to add a quote from the paper. I thought Kathryn Graddy explained the IV estimation well:

> That is, first a regression is run with log price as the dependent variable and the storminess of the weather as the explanatory variable. This regression seeks to measure the variation in price that is attributable to stormy weather. The coefficients from this regression are then used to predict log price on each day, and these predicted values for price are inserted back into the regression.

Now let's move on to using IV. This is possible with the `brms` package and its ability to specify multivariate models. We'll piece it together with two separate formulas defined in the `bf` function calls below.

The first estimation will be for column `3` of table `2`:

```{r}
# measure variation in price attributable to stormy weather
fit2a <- bf(price ~ stormy)
# estimate demand
fit2b <- bf(qty ~ price)

# column 3 in table 2
fit2 <- brm(fit2a + fit2b, data = fulton, refresh = 0)

fit2 %>% 
  posterior_samples() %>% 
  ggplot(aes(x = b_qty_price)) +
    geom_density_line()
```

And lastly we'll estimate the IV with the remaining variables (column `4`):

```{r}
# add additional demand specific variables
fit2b_full <- bf(qty ~ price + day1 + day2 + day3 + day4 + cold + rainy)

# column 4 in table 2
fit2_full <- brm(fit2a + fit2b_full, data = fulton, refresh = 0)

fit2_full %>% 
  posterior_samples() %>% 
  gather(b_qty_price:b_qty_rainy, key = "coef", value = "est") %>% 
  ggplot(aes(x = est, y = coef)) +
    geom_density_ridges()
```

### Visualizing the Demand Curve

Now we can plot the demand curve with isolated demand effects. I'll use the first IV estimation with only `qty`, `price`, and `stormy` variables:

```{r}
fulton %>% 
  add_predicted_draws(fit2) %>% 
  filter(.category == "qty") %>% 
  ggplot(aes(x = price, y = qty)) +
  stat_lineribbon(
    aes(y = .prediction), 
    .width = c(.99, .95, .8, .5), 
    color = "#08519C"
    ) +
  geom_point(data = fulton, size = 2) +
  scale_fill_brewer()
```

The prediction is downward trending as the original curve except with a steeper slope (`` `r round(fixef(fit1)["price","Estimate"], 2)` `` vs `` `r round(fixef(fit2)["qty_price", "Estimate"], 2)` ``).

## Elasticities

The paper breaks down the interpretation of the estimated coefficients in terms of elasticities. Given that we have taken the `log` of both our quantity and price the coefficients can be interpreted in a clever way. Let's take a look at why this is the case:

If we take the log of both $y$ and $x$:

$$
\text{log}(y) = \beta_0 + \beta_1\text{log}(x) + \epsilon
$$
Now solve for $y$ to find the marginal effects:

$$
y = e^{\beta_o + \beta_1\text{log}(x) + \epsilon}
$$
Then differentiate with respect to $x$:

$$
\frac{dy}{dx} = \frac{\beta_1}{x}e^{\beta_o + \beta_1\text{log}(x) + \epsilon} = \beta_1 \frac{y}{x}
$$

If you then solve for $\beta_1$ you find:

$$
\beta_1 = \frac{dy}{dx} \frac{x}{y}
$$
So here $\beta_1$ is an elasticity. For a unit increase in $x$ there is a $\beta_1 \%$ increase in $y$.

Elasticities are commonly summarized in a table like this:

Elasticity | Value | Description
------ | ----- | -----
Elastic  | \| *E* \| > 1 | % change in *Q* > % change in *P*
Unitary Elastic | \| *E* \|  = 1 | % change in *Q* = %change in *P* 
Inelastic | \| *E* \|  < 1| % change in *Q* < % change in *P* 

Given the descriptions of elasticity above. We would have two different interpretations of how demand responds to price with the non-IV and the IV estimation. With the non-IV estimation our elasticity coefficient is `` `r round(fixef(fit1)["price","Estimate"], 2)` `` [`r round(fixef(fit1)["price","Q2.5"], 2)`, `r round(fixef(fit1)["price","Q97.5"], 2)`]. With the IV estimation our elasticity is `` `r round(fixef(fit2)["qty_price", "Estimate"], 2)` `` [`r round(fixef(fit2)["qty_price", "Q2.5"], 2)`, `r round(fixef(fit2)["qty_price", "Q97.5"], 2)`]. So we would mistakenly interpret the demand elasticity as being inelastic when it actually appears to be unitary elastic. 

Some interesting interpretations of this unit elasticity from the paper include:

> First, it is consistent with pricing power on the part of the
fish dealers. A price-setting firm will raise price to the point where the percentage change in the quantity demanded is at least as large as the percentage change in price; otherwise, it would make sense to raise the price even more

>  Second, when demand has a unitary elasticity, it means that the percentage change in quantity would always equal the percentage change in price, and the weather would therefore not have much effect on a seller’s revenue, keeping fishermen’s incomes relatively constant.

> Third, unit elasticities could also result from budget constraints on the part of some buyers.

## Wrapping Up

This was definitely a fun topic to begin exploring. I plan on taking a look at *difference-in-differences* in the near future as well.

## References

* [DataFramed: The Credibility Crisis in Data Science](https://www.datacamp.com/community/podcast/credibility-crisis-in-data-science)
* [Graddy, Kathryn. 2006. "Markets: The Fulton Fish Market." Journal of Economic Perspectives, 20 (2): 207-220.](https://www.aeaweb.org/articles?id=10.1257/jep.20.2.207)
* [Create supply and demand economics curves with ggplot2](https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/)
* [Log-level and Log-log transformations in Linear Regression Models](http://home.wlu.edu/~gusej/econ398/notes/logRegressions.pdf)
