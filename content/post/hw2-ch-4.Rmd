---
title: "Homework 2, Chapter 4"
author: "J. Duncan"
date: 2019-03-10T21:13:14-05:00
tags:
- rstats
- bayes
output:
  blogdown::html_page:
    dev: "svg"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Hard Problems

### 4H1.

The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals. That is, fill in the table below, using model-based predictions.

```{r}
library(tidyverse)
library(knitr)
library(kableExtra)

kung <- tibble::tribble(
  ~individual, ~weight,
            1,   46.95,
            2,   43.72,
            3,   64.78,
            4,   32.59,
            5,   54.63
  )

# kable(kung, digits = 3, row.names = FALSE, align = "c", caption = NULL) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

Well it looks like first we need to estimate this model. In the book on page `96` we see the MAP estimation of this model on the filtered dataset. I'm going to fit this one for predictions.

```{r}
library(rethinking)
data("Howell1")

d <- Howell1
d2 <- d[d$age >= 18, ]

# fit model
m4.3 <- rethinking::map(
  alist(
    height ~ dnorm(mu, sigma), # likelihood
    mu <- a + b * weight, # linear model
    a ~ dnorm(156, 100), # prior
    b ~ dnorm(0, 10), # prior
    sigma ~ dunif(0, 50) # prior
  ),
  data = d2
)
```

Now the model is fit and we can estimate the predictions in two ways:

1. Collect posterior samples of the parameters of the estimated model and for each weight in the above dataframe sample from a Normal distribution with our posterior samples as parameters
2. Use the convenience function in the `rethinking` package called `sim()` to do the above giving it only the new weights

```{r}
post <- extract.samples(m4.3)
head(post)

sim.height <- sapply(kung$weight, function(weight)
  rnorm(
    n = nrow(post),
    mean = post$a + post$b * weight,
    sd = post$sigma
    )
  )

(sim.PI <- apply(sim.height, 2, PI, prob = 0.89))
```

And the convenient way:

```{r}
sim.height <- sim(m4.3, data = list(weight = kung$weight))
(sim.PI <- apply(sim.height, 2, PI, prob = 0.89))
```

We have relatively the same results here which is expected. Let's get the mean values as well:

```{r}
sim.mean <- apply(sim.height, 2, mean)
```

Now let's put all of this in the dataframe:

```{r}
kung$exp_height <- sim.mean
kung$lo_89 <- sim.PI[1,]
kung$hi_89 <- sim.PI[2,]

# kable(kung, digits = 3, row.names = FALSE, align = "c", caption = NULL) %>%
#   kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

## 4H2.

Select out all the rows in the `Howell1` data with ages below 18 years of age. If you do it right you should end up with a new data frame with 192 rows in it.

```{r}
d3 <- d[d$age < 18,]
```

### (a)
> Fit a linear regression to these data, using `map`. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets?

```{r}
fit <- rethinking::map(
  alist(
    height ~ dnorm(mu, sigma), # likelihood
    mu <- a + b * weight, # linear model
    a ~ dnorm(156, 100), # prior
    b ~ dnorm(0, 10), # prior
    sigma ~ dunif(0, 50) # prior
  ),
  data = d3
)
```

Let's look at the results of this model:

```{r}
post_early <- extract.samples(fit)
precis(post_early)
```

So we see for every `1` unit increase in weight a child should be `2.72` cm taller. Or as the question has asked `10` unit increase is a `27.2` cm increase in height. For every `22` lb increase there is a corresponding ~`1` foot increase in height.

### (b)
> Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the 89% HPDI for predicted heights.

```{r}
plot(height ~ weight, d3, col = col.alpha(rangi2, 0.5))

# get index for calculations
weight.seq <- seq(0, 50, by = 1)

# extract samples of parameters and calculate expected mu
mu <- link(fit, data = data.frame(weight = weight.seq))
mu.mean <- apply(mu, 2, mean)
lines(weight.seq, mu.mean)
mu.HPDI <- apply(mu, 2, HPDI)
shade(mu.HPDI, weight.seq)

# simulate posterior observations of the model fit
sim.height <- sim(fit, data = data.frame(weight = weight.seq))
height.HPDI <- apply(sim.height, 2, HPDI)
shade(height.HPDI, weight.seq)
```

### (c)
> What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don't have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.

Well the model appears to be doing good job with the data at hand. The prior's were set for persons age > 18 so these should be adjusted. Something of conrern is that you see a non-linear structure in this data. So the two tails of the data are not covered well by the model. This non-linearity could be accounted for with a polynomial regression or with splines.

## 4H3.
Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, "That's silly. Everyone knows that it's only the **logarithm** of body weight that scales with height!" Let's take your colleague's advice and see what happens.

### (a)
> Model the relationship between height(cm) and the natural logarithm of weight (log-kg). Use the entire `Howell1` data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation:

$$
\begin{aligned}
h_i \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i = \alpha + \beta \text{log}(w_i) \\
\alpha \sim \text{Normal}(178, 100) \\
\beta \sim \text{Normal}(0, 100) \\
\sigma \sim \text{Uniform}(0, 50)
\end{aligned}
$$
where $h_i$ is the height of individual $i$ and $w_i$ is the weight (in kg) of individual $i$. The function for computing a natural log in R is just `log`. Can you interpret the resulting estimates?

```{r}
fit_all <- rethinking::map(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b * log(weight), # linear model
    a ~ dnorm(178, 100),
    b ~ dnorm(0, 100),
    sigma ~ dunif(0, 50)
  ),
  data = d
)
```

Now the model is fit let's review the coefficients.
```{r}
precis(fit_all)
plot(precis(fit_all))
```

When the weight is low or equivalent to `1` then the height would be `-23` which is not insightful. Given that this is a log-level model we can [interpret](https://stats.stackexchange.com/questions/18480/interpretation-of-log-transformed-predictor) our $\beta$ as a one percent increase in weight corresponds to a $\beta/100 = 47.08/100$ unit increase in height.

### (b)

Begin with this plot:

```{r}
plot(height ~ weight, data = d, col = col.alpha(rangi2, 0.4))
```

Then use the samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and (3) the 97% HPDI for predicted heights.

```{r}
weight.seq <- seq(2, 65, by = 1)
all_samp <- link(fit_all, data = data.frame(weight = weight.seq))
all_mu <- apply(all_samp, 2, mean)
all_mu.HPDI <- apply(all_samp, 2, HPDI, prob = 0.97)

all_sim <- sim(fit_all, data = data.frame(weight = weight.seq))
all_sim.HPDI <- apply(all_sim, 2, HPDI, prob = 0.97)

plot(height ~ weight, data = d, col = col.alpha(rangi2, 0.4))
# the predicted mean height
lines(weight.seq, all_mu)
# the 97% HPDI of the mean
shade(all_mu.HPDI, weight.seq)
# the 97% HPDI for predictions
shade(all_sim.HPDI, weight.seq)
```
