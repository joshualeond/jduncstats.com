[
  {
    "path": "bayes-hackr/2021-01-08-bayes-hackr-ch1/",
    "title": "Chapter 1",
    "description": "Reproducing Chapter 1 of Bayesian Methods for Hackers in R + Stan",
    "author": [
      {
        "name": "J. Duncan",
        "url": {}
      }
    ],
    "date": "2021-01-08",
    "categories": [],
    "contents": "\n1.4 Using Computers to Perform Bayesian Inference for Us\n1.4.1 Example: Inferring Behavior from Text-Message Data\n\n\nlibrary(tidyverse)\nlibrary(cmdstanr)\nlibrary(posterior)\nlibrary(bayesplot)\nlibrary(tidybayes)\nlibrary(latex2exp)\n\nurl <- \"https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter1_Introduction/data/txtdata.csv\"\n\ndata <- read_csv(url, col_names = FALSE) %>% \n  rename(count = X1) %>% \n  mutate(day = row_number())\n\n\n\nLet’s visualize this data to make sure all is well:\n\n\ntheme_set(theme_tidybayes())\n\ndata %>% \n  ggplot(aes(x=day, y=count)) + \n  geom_col() +\n  labs(\n    title = \"Did the user's texting habits change over time?\",\n    x = \"Time (days)\",\n    y = \"count of text-msgs received\"\n  ) \n\n\n\n\n1.4.2 Introducing Our First Hammer: PyMC Stan\nThis is where things get interesting. The original model included a discrete random variable \\(\\tau\\) that was modeled with a Discrete Uniform distribution. Then they sampled with the Metropolis algorithm so it was possible to sample from a joint distribution including this discrete parameter.\nA limitation (I suppose) of the main algorithm used by Stan, HMC, is that everything must be differentiable and so discrete parameters are off the table. However, with a little statistical theory you’re still able to estimate this model and even the posterior of \\(\\tau\\) by marginalizing the parameter out of the probability function. Then recovering this parameter afterwards in the generated quantities block!\nSee the Stan manual as well as this blog post for more info on implementing this model and the marginalization process.\n\n\ndata_list <- tidybayes::compose_data(data)\ndata_list[['alpha']] <- 1 / mean(data_list$count)\ndata_list\n\n\n$count\n [1] 13 24  8 24  7 35 14 11 15 11 22 22 11 57 11 19 29  6 19 12 22 12\n[23] 18 72 32  9  7 13 19 23 27 20  6 17 13 10 14  6 16 15  7  2 15 15\n[45] 19 70 49  7 53 22 21 31 19 11 18 20 12 35 17 23 17  4  2 31 30 13\n[67] 27  0 39 37  5 14 13 22\n\n$day\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n[23] 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44\n[45] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66\n[67] 67 68 69 70 71 72 73 74\n\n$n\n[1] 74\n\n$alpha\n[1] 0.05065024\n\nHere’s the Stan code used for estimating this joint probability distribution:\n\ndata {\n  int<lower=1> n;\n  int<lower=0> count[n];\n  real alpha;\n}\n\ntransformed data {\n  real log_unif;\n  log_unif = -log(n);\n}\n\nparameters {\n  real<lower=0> lambda_1;\n  real<lower=0> lambda_2;\n}\n\ntransformed parameters {\n  vector[n] lp;\n  lp = rep_vector(log_unif, n);\n  for (tau in 1:n)\n    for (i in 1:n)\n      lp[tau] += poisson_lpmf(count[i] | i < tau ? lambda_1 : lambda_2);\n}\n\nmodel {\n  lambda_1 ~ exponential(alpha);\n  lambda_2 ~ exponential(alpha);\n  target += log_sum_exp(lp);\n}\n\ngenerated quantities {\n  int<lower=1,upper=n> tau;\n  vector<lower=0>[n] expected;\n  // posterior of discrete change point\n  tau = categorical_logit_rng(lp);\n  // predictions for each day\n  for (day in 1:n)\n    expected[day] = day < tau ? lambda_1 : lambda_2;\n}\n\n\nNow for sampling from the distribution and obtaining the marginal distributions:\n\n\nmod <- cmdstanr::cmdstan_model(\"models/ch1-mod.stan\")\n\nfit <- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 11.5 seconds.\nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 12.9 seconds.\nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 13.1 seconds.\nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 13.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 12.9 seconds.\nTotal execution time: 14.4 seconds.\n\nfit$summary()\n\n\n# A tibble: 152 x 10\n   variable   mean median    sd   mad     q5    q95  rhat ess_bulk\n   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>\n 1 lp__     -481.  -481.  1.13  0.715 -483.  -480.   1.00    4770.\n 2 lambda_1   17.8   17.7 0.678 0.646   16.7   18.8  1.00    6623.\n 3 lambda_2   22.7   22.7 0.981 0.889   21.2   24.2  1.00    8000.\n 4 lp[1]    -512.  -511.  9.47  8.46  -529.  -500.   1.00    9227.\n 5 lp[2]    -511.  -509.  9.16  8.10  -526.  -499.   1.00    9025.\n 6 lp[3]    -512.  -510.  9.13  8.14  -527.  -500.   1.00    9516.\n 7 lp[4]    -509.  -507.  8.71  7.58  -524.  -498.   1.00    9131.\n 8 lp[5]    -510.  -508.  8.67  7.61  -524.  -499.   1.00    9471.\n 9 lp[6]    -506.  -505.  8.25  7.01  -520.  -496.   1.00    9095.\n10 lp[7]    -510.  -509.  8.48  7.46  -525.  -499.   1.00    9637.\n# … with 142 more rows, and 1 more variable: ess_tail <dbl>\n\n\n\n# https://mpopov.com/blog/2020/09/07/pivoting-posteriors/\ntidy_draws.CmdStanMCMC <- function(model, ...) {\n  return(as_draws_df(model$draws()))\n}\n\n\n\nLet’s visualize the marginal distributions of \\(\\lambda_1\\) and \\(\\lambda_2\\):\n\n\ndraws_df <- as_draws_df(fit$draws(c(\"lambda_1\", \"lambda_2\", \"tau\")))\n\ndraws_df %>% \n  gather_draws(lambda_1, lambda_2) %>%\n  ggplot(aes(y = .variable, x = .value)) +\n  stat_dotsinterval(quantiles = 100) +\n  labs(\n    title = TeX(\"Posterior Distributions of $\\\\lambda_1$ and $\\\\lambda_2$\"),\n    y = NULL\n  )\n\n\n\n\nReviewing when the change point occurred:\n\n\ndraws_df %>% \n  gather_draws(tau) %>% \n  ggplot(aes(x = .value)) +\n  geom_bar(aes(y = ..count../sum(..count..))) +\n  scale_x_continuous(breaks = scales::pretty_breaks(10), limits = c(40, 50)) +\n  labs(\n    title = TeX(\"Posterior Distribution of $\\\\tau$\"),\n    y = \"probability\",\n    x = TeX(\"$\\\\tau$ (in days)\")\n  ) \n\n\n\n\n\nOur analysis also returned a distribution for \\(\\tau\\). Its posterior distribution looks a little different from the other two because it is a discrete random variable, so it doesn’t assign probabilities to intervals. We can see that near day 46, there was a 50% chance that the user’s behaviour changed. Had no change occurred, or had the change been gradual over time, the posterior distribution of \\(\\tau\\) would have been more spread out, reflecting that many days were plausible candidates for \\(\\tau\\). By contrast, in the actual results we see that only three or four days make any sense as potential transition points.\n\n1.4.4 What Good Are Samples from the Posterior, Anyways?\nNow for calculating the expected values:\n\n\npredictions <- fit$draws(\"expected\") %>% \n  as_draws_df() %>% \n  spread_draws(expected[day])\n\npredictions\n\n\n# A tibble: 888,000 x 5\n# Groups:   day [74]\n     day expected .chain .iteration .draw\n   <int>    <dbl>  <int>      <int> <int>\n 1     1     18.8      1          1     1\n 2     1     16.8      1          2     2\n 3     1     17.9      1          3     3\n 4     1     18.3      1          4     4\n 5     1     17.3      1          5     5\n 6     1     17.8      1          6     6\n 7     1     17.8      1          7     7\n 8     1     17.7      1          8     8\n 9     1     16.4      1          9     9\n10     1     17.9      1         10    10\n# … with 887,990 more rows\n\nLet’s visualize these predictions now including the uncertainty around our \\(\\lambda\\) parameters:\n\n\npredictions %>% \n  mean_qi(.width = c(.99, .95, .8)) %>% \n  ggplot(aes(x = day)) +\n  geom_col(data = data, aes(y = count)) +\n  geom_lineribbon(aes(y = expected, ymin = .lower, ymax = .upper), color = \"#08519C\") +\n  labs(\n    title = \"Expected number of text-messages received\",\n    x = \"Time (days)\",\n    y = \"Expected # text-messages\"\n  ) +\n  scale_fill_brewer() \n\n\n\n\n1.6 Appendix\n1.6.1 Determining Statistically if the Two \\(\\lambda\\)s Are Indeed Different?\nNow for reviewing the difference between these two \\(\\lambda\\)’s. In the book he answers this question with explicit probabilities but we can also represent the same question with a data visualization. This shows us that the probability that these \\(\\lambda\\)s differ by at least 5 times is 50%.\n\n\ndraws_df %>% \n  gather_draws(lambda_1, lambda_2) %>%\n  compare_levels(.value, by = .variable) %>% \n  ggplot(aes(y = .variable, x = .value, fill = stat(abs(x) < 5))) +\n  stat_halfeye() +\n  geom_vline(xintercept = c(-5,5), linetype = \"dashed\") +\n  scale_fill_manual(values = c(\"gray80\", \"skyblue\")) +\n  labs(\n    title = \"Comparing our parameters\",\n    y = NULL\n  )\n\n\n\n\n\n\n\n",
    "preview": "bayes-hackr/2021-01-08-bayes-hackr-ch1/bayes-hackr-ch1_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-03-18T22:00:14-05:00",
    "input_file": {}
  },
  {
    "path": "bayes-hackr/2021-01-08-bayes-hackr-ch2/",
    "title": "Chapter 2",
    "description": "Reproducing Chapter 2 of Bayesian Methods for Hackers in R + Stan",
    "author": [
      {
        "name": "J. Duncan",
        "url": {}
      }
    ],
    "date": "2021-01-08",
    "categories": [],
    "contents": "\n2.2 Modeling Approaches\n2.2.10 Example: Challenger Space Shuttle Disaster\n\n\nlibrary(tidyverse)\nlibrary(cmdstanr)\nlibrary(posterior)\nlibrary(bayesplot)\nlibrary(tidybayes)\nlibrary(latex2exp)\nlibrary(modelr)\n\nurl <- \"https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter2_MorePyMC/data/challenger_data.csv\"\n\ndata <- read_csv(url, col_types = \"cdi\") %>% \n  janitor::clean_names() %>% \n  mutate(\n    date = if_else(\n      nchar(date) >= 10,\n      parse_date(date, format = \"%m/%d/%Y\"),\n      parse_date(date, format = \"%m/%d/%y\")\n      )\n    ) %>% \n  drop_na()\n\n\n\nLet’s visualize this data to make sure all is well:\n\n\ntheme_set(theme_tidybayes())\n\ndata %>% \n  ggplot(aes(x=temperature, y=damage_incident)) + \n  geom_point(alpha = 0.5) +\n  labs(\n    title = \"Defects of the Space Shuttle O-Rings vs temperature\",\n    x = \"Outside temperautre (Farenheit)\",\n    y = \"Damage Incident\"\n  ) +\n  scale_y_continuous(breaks = scales::pretty_breaks(n = 1)) +\n  xlim(50, 85)\n\n\n\n\nhttps://jrnold.github.io/bayesian_notes/binomial-models.html\n\n\nmap_df(\n  list(-1, -3, 5),\n  ~ tibble(\n    x = seq(-4, 4, length.out = 101),\n    y = plogis(x * .x),\n    Parameter = paste0(\"Beta: \", .x)\n    )\n  ) %>%\n  ggplot(aes(x = x, y = y, colour = Parameter)) +\n  geom_line() \n\n\n\n\n2.2.11 The Normal Distribution\n\n\ndata_list <- data %>% \n  rename(damage = damage_incident) %>% \n  compose_data()\n\n\n\n\n\nmod <- cmdstanr::cmdstan_model(\"models/ch2-mod.stan\")\nmod$print()\n\n\ndata {\n  int<lower=0> n;\n  vector[n] temperature;\n  int<lower=0,upper=1> damage[n];\n}\n\nparameters {\n  real alpha;\n  real beta;\n}\n\nmodel {\n  alpha ~ normal(0, sqrt(1000));\n  beta ~ normal(0, sqrt(1000));\n  damage ~ bernoulli_logit(beta * temperature + alpha);\n}\n\ngenerated quantities {\n  vector[n] yrep;\n  for (i in 1:n){\n    yrep[i] = bernoulli_logit_rng(beta * temperature[i] + alpha);\n  }\n}\n\nfit <- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.8 seconds.\nChain 2 finished in 0.9 seconds.\nChain 3 finished in 0.9 seconds.\nChain 4 finished in 0.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.9 seconds.\nTotal execution time: 1.1 seconds.\n\nfit$summary()\n\n\n# A tibble: 26 x 10\n   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk\n   <chr>      <dbl>   <dbl> <dbl> <dbl>   <dbl>   <dbl> <dbl>    <dbl>\n 1 lp__     -11.3   -11.0   1.02  0.743 -13.3   -10.3    1.00    2616.\n 2 alpha     17.4    16.6   7.77  7.66    6.16   31.2    1.00    1526.\n 3 beta      -0.267  -0.256 0.114 0.112  -0.469  -0.104  1.00    1536.\n 4 yrep[1]    0.448   0     0.497 0       0       1      1.00   11428.\n 5 yrep[2]    0.232   0     0.422 0       0       1      1.00   11617.\n 6 yrep[3]    0.270   0     0.444 0       0       1      1.00   11845.\n 7 yrep[4]    0.327   0     0.469 0       0       1      1.00   11921.\n 8 yrep[5]    0.376   0     0.484 0       0       1      1.00   11480.\n 9 yrep[6]    0.156   0     0.363 0       0       1      1.00   11547.\n10 yrep[7]    0.128   0     0.334 0       0       1      1.00   10240.\n# … with 16 more rows, and 1 more variable: ess_tail <dbl>\n\nhttps://mpopov.com/blog/2020/09/07/pivoting-posteriors/\n\n\ntidy_draws.CmdStanMCMC <- function(model, ...) {\n  return(as_draws_df(model$draws()))\n}\n\n\n\n\n\nfit %>% \n  gather_draws(alpha, beta) %>% \n  ggplot(aes(x = .value)) +\n  geom_histogram() +\n  facet_wrap(~.variable, scales = \"free\", ncol = 1) +\n  labs(\n    title = TeX(\"Posterior Distributions of $\\\\alpha$ and $\\\\beta$\"),\n    y = NULL\n  )\n\n\n\n\nUsing comments from discourse:\n\nExtract posterior parameter samples into R and do prediction in R with new-data-for-prediction.\n\n\n\npost_df <- spread_draws(fit, alpha, beta)\nt <- seq(min(data$temperature) - 5, max(data$temperature) + 5, length.out = 50)\n\npred_df <- tibble(temperature = t) %>% \n  mutate(nest(post_df)) %>% # nest all posterior parameters samples\n  mutate(\n    data = map2(\n      data, \n      temperature, \n      ~ mutate(.x, pred = plogis(alpha + beta * .y)) # predict\n    )\n  ) %>% \n  unnest(data)\n\n\n\nNow for the visualizations. First let’s look at realizations and then will summarize all of the realizations:\n\n\npred_df %>% \n  group_by(temperature) %>% \n  sample_draws(100) %>% \n  ggplot(aes(x = temperature)) +\n  geom_line(aes(y = pred, group = .draw), alpha = 0.3) + \n  geom_point(data = data, aes(y = damage_incident), alpha = 0.3) +\n  labs(\n    title = \"Posterior probability estimates given temp; realizations\",\n    y = \"probability estimate\"\n  )\n\n\n\n\nNow for all of the realizations:\n\n\npred_df %>% \n  group_by(temperature) %>% \n  median_hdci(pred, .width = c(0.95, 0.8)) %>% \n  ggplot(aes(x = temperature)) +\n  geom_lineribbon(aes(y = pred, ymin = .lower, ymax = .upper), color = \"#08519C\") +\n  geom_point(data = data, aes(y = damage_incident), alpha = 0.5) +\n  scale_fill_brewer() +\n  labs(\n    title = \"Posterior probability estimates given temp\",\n    y = \"probability estimate\"\n  )\n\n\n\n\n2.2.12 What about the day of the Challenger disaster?\n\nOn the day of the Challenger disaster, the outside temperature was 31 degrees Fahrenheit. What is the posterior distribution of a defect occurring, given this temperature? The distribution is plotted below. It looks almost guaranteed that the Challenger was going to be subject to defective O-rings.\n\n\n\nprob_31 <- post_df %>% \n  mutate(pred = plogis(alpha + beta * 31))\n\nprob_31 %>% \n  ggplot(aes(x = pred)) +\n  stat_dots(quantiles = 25) +\n  labs(\n    title = TeX(\"Posterior distribution of probability of defect, given $t = 31$\"),\n    x = \"probability of defect occurring in O-ring\",\n    y = NULL\n  )\n\n\n\n\n2.3 Is Our Model Appropriate?\n2.3.1 Separation Plots\nWhere expected number of defects for the Bernoulli random variable is given as:\n\\[\nE[S] = \\sum_{i=0}^N E[X_i] = \\sum_{i=0}^N p_i\n\\] Preparing our data for the separation plot:\n\n\nsep_data <- fit %>% \n  spread_draws(yrep[day]) %>% \n  mean_hdci(yrep) %>% \n  left_join(mutate(data, day = row_number())) %>% \n  arrange(yrep) %>% \n  mutate(idx = row_number())\n\nexp_def <- sep_data %>% \n  summarize(exp_def = sum(yrep)) %>% \n  pull()\n\n\n\nNow let’s review the separation plot:\n\n\nsep_data %>% \n  ggplot(aes(x=idx)) +\n  geom_col(aes(y=damage_incident), alpha = 0.3) +\n  geom_step(aes(y = yrep)) +\n  geom_vline(xintercept = 23 - exp_def, linetype = \"dotted\") +\n  labs(\n    title = \"Separation Plot\",\n    subtitle = paste0(\"with \", round(exp_def, 1), \" expected defects\"),\n    y = NULL,\n    x = NULL\n  )\n\n\n\n\n\nThe snaking-line is the sorted probabilities, blue gray bars denote defects, and empty space denote non-defects. As the probability rises, we see more and more defects occur. On the right hand side, the plot suggests that as the posterior probability is large (line close to 1), then more defects are realized. This is good behaviour. Ideally, all the blue gray bars should be close to the right-hand side, and deviations from this reflect missed predictions.\n\n\n\n\n",
    "preview": "bayes-hackr/2021-01-08-bayes-hackr-ch2/bayes-hackr-ch2_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-03-18T22:00:14-05:00",
    "input_file": {}
  },
  {
    "path": "bayes-hackr/2021-01-08-bayes-hackr-ch3/",
    "title": "Chapter 3",
    "description": "Reproducing Chapter 3 of Bayesian Methods for Hackers in R + Stan",
    "author": [
      {
        "name": "J. Duncan",
        "url": {}
      }
    ],
    "date": "2021-01-08",
    "categories": [],
    "contents": "\n3.1 The Bayesian Landscape\n3.1.4 Example: Unsupervised Clustering Using a Mixture Model\n\n\nlibrary(tidyverse)\nlibrary(cmdstanr)\nlibrary(posterior)\nlibrary(bayesplot)\nlibrary(tidybayes)\nlibrary(rstan)\nlibrary(patchwork)\nlibrary(distributional)\n\nurl <- \"https://raw.githubusercontent.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Chapter3_MCMC/data/mixture_data.csv\"\n\ndata <- read_csv(url, col_names = FALSE) %>% \n  rename(x = X1)\n\n\n\nLet’s visualize this data to make sure all is well:\n\n\ntheme_set(theme_tidybayes())\n\ndata %>% \n  ggplot(aes(x=x)) + \n  stat_histinterval() +\n  labs(\n    title = \"Mixture Data\",\n    x = \"Value\",\n    y = NULL\n  ) \n\n\n\n\n\n\ndata_list <- list(\n  N = 300,\n  K = 2, # number of clusters\n  y = data$x\n)\n\n\n\nhttps://mc-stan.org/docs/2_25/stan-users-guide/summing-out-the-responsibility-parameter.html\n\n\nmod <- cmdstanr::cmdstan_model(\"models/ch3-mod.stan\")\nmod$print()\n\n\ndata {\n  int<lower=1> K;          // number of mixture components\n  int<lower=1> N;          // number of data points\n  real y[N];               // observations\n}\n\nparameters {\n  simplex[K] theta;          // mixing proportions\n  ordered[K] mu;             // locations of mixture components\n  vector<lower=0>[K] sigma;  // scales of mixture components\n}\n\nmodel {\n  vector[K] log_theta = log(theta);  // cache log calculation\n  sigma ~ uniform(0, 100);\n  mu[1] ~ normal(120, 10);\n  mu[2] ~ normal(190, 10);\n  \n  for (n in 1:N) {\n    vector[K] lps = log_theta;\n    for (k in 1:K)\n      lps[k] += normal_lpdf(y[n] | mu[k], sigma[k]);\n    target += log_sum_exp(lps);\n  }\n}\n\ngenerated quantities {\n  vector[N] yrep;\n  for (i in 1:N){\n    vector[K] log_theta = log(theta);\n    yrep[i] = (normal_lpdf(y[i] | mu[1], sigma[1]) + log_theta[1]) >\n    (normal_lpdf(y[i] | mu[2], sigma[2]) + log_theta[2]);\n  }\n}\n\nfit <- mod$sample(\n  data = data_list,\n  seed = 123,\n  chains = 2,\n  parallel_chains = 2,\n  refresh = 1000,\n  iter_warmup = 4000,\n  iter_sampling = 8000\n)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 Iteration:     1 / 12000 [  0%]  (Warmup) \nChain 2 Iteration:     1 / 12000 [  0%]  (Warmup) \nChain 2 Iteration:  1000 / 12000 [  8%]  (Warmup) \nChain 1 Iteration:  1000 / 12000 [  8%]  (Warmup) \nChain 1 Iteration:  2000 / 12000 [ 16%]  (Warmup) \nChain 2 Iteration:  2000 / 12000 [ 16%]  (Warmup) \nChain 1 Iteration:  3000 / 12000 [ 25%]  (Warmup) \nChain 1 Iteration:  4000 / 12000 [ 33%]  (Warmup) \nChain 1 Iteration:  4001 / 12000 [ 33%]  (Sampling) \nChain 1 Iteration:  5000 / 12000 [ 41%]  (Sampling) \nChain 1 Iteration:  6000 / 12000 [ 50%]  (Sampling) \nChain 1 Iteration:  7000 / 12000 [ 58%]  (Sampling) \nChain 1 Iteration:  8000 / 12000 [ 66%]  (Sampling) \nChain 1 Iteration:  9000 / 12000 [ 75%]  (Sampling) \nChain 1 Iteration: 10000 / 12000 [ 83%]  (Sampling) \nChain 1 Iteration: 11000 / 12000 [ 91%]  (Sampling) \nChain 1 Iteration: 12000 / 12000 [100%]  (Sampling) \nChain 1 finished in 34.0 seconds.\nChain 2 Iteration:  3000 / 12000 [ 25%]  (Warmup) \nChain 2 Iteration:  4000 / 12000 [ 33%]  (Warmup) \nChain 2 Iteration:  4001 / 12000 [ 33%]  (Sampling) \nChain 2 Iteration:  5000 / 12000 [ 41%]  (Sampling) \nChain 2 Iteration:  6000 / 12000 [ 50%]  (Sampling) \nChain 2 Iteration:  7000 / 12000 [ 58%]  (Sampling) \nChain 2 Iteration:  8000 / 12000 [ 66%]  (Sampling) \nChain 2 Iteration:  9000 / 12000 [ 75%]  (Sampling) \nChain 2 Iteration: 10000 / 12000 [ 83%]  (Sampling) \nChain 2 Iteration: 11000 / 12000 [ 91%]  (Sampling) \nChain 2 Iteration: 12000 / 12000 [100%]  (Sampling) \nChain 2 finished in 82.3 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 58.2 seconds.\nTotal execution time: 82.4 seconds.\n\nfit$summary()\n\n\n# A tibble: 307 x 10\n   variable     mean   median     sd    mad       q5      q95  rhat\n   <chr>       <dbl>    <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>\n 1 lp__     -1.54e+3 -1.54e+3 1.67   1.47   -1.54e+3 -1.53e+3  1.00\n 2 theta[1]  3.77e-1  3.73e-1 0.0507 0.0475  3.01e-1  4.65e-1  1.00\n 3 theta[2]  6.23e-1  6.27e-1 0.0507 0.0475  5.35e-1  6.99e-1  1.00\n 4 mu[1]     1.20e+2  1.20e+2 5.71   5.31    1.12e+2  1.30e+2  1.00\n 5 mu[2]     2.00e+2  2.00e+2 2.62   2.64    1.95e+2  2.04e+2  1.00\n 6 sigma[1]  3.02e+1  2.98e+1 4.07   3.80    2.44e+1  3.77e+1  1.00\n 7 sigma[2]  2.28e+1  2.28e+1 1.91   1.87    1.99e+1  2.61e+1  1.00\n 8 yrep[1]   1.00e+0  1.00e+0 0      0       1.00e+0  1.00e+0 NA   \n 9 yrep[2]   8.40e-1  1.00e+0 0.367  0       0.       1.00e+0  1.00\n10 yrep[3]   2.75e-3  0.      0.0524 0       0.       0.       1.00\n# … with 297 more rows, and 2 more variables: ess_bulk <dbl>,\n#   ess_tail <dbl>\n\nposterior <- fit$output_files() %>% \n  read_stan_csv()\n\n\n\n\n\np1 <- posterior %>% \n  mcmc_trace(pars = c(\"mu[1]\", \"mu[2]\")) +\n  labs(\n    title = \"Traces of center for each cluster\"\n  )\n\np2 <- posterior %>% \n  mcmc_trace(pars = c(\"sigma[1]\", \"sigma[2]\")) +\n  labs(\n    title = \"Traces of standard deviation of each cluster\"\n  )\n\np3 <- posterior %>% \n  mcmc_trace(pars = c(\"theta[1]\")) +\n  labs(\n    title = \"Frequency of assignment to cluster 1\"\n  )\n\np1 / p2 / p3 \n\n\n\n\n\nNotice the following characteristics:\nThe traces converges, not to a single point, but to a distribution of possible points. This is convergence in an MCMC algorithm.\nInference using the first few thousand points is a bad idea, as they are unrelated to the final distribution we are interested in. Thus is it a good idea to discard those samples before using the samples for inference. We call this period before converge the burn-in period.\nThe traces appear as a random “walk” around the space, that is, the paths exhibit correlation with previous positions. This is both good and bad. We will always have correlation between current positions and the previous positions, but too much of it means we are not exploring the space well. This will be detailed in the Diagnostics section later in this chapter.\n\nCluster Investigation\n\n\n# https://mpopov.com/blog/2020/09/07/pivoting-posteriors/\ntidy_draws.CmdStanMCMC <- function(model, ...) {\n  return(as_draws_df(model$draws()))\n}\n\n\n\n\n\nfit %>% \n  gather_draws(mu[cluster], sigma[cluster]) %>% \n  mutate(cluster = paste0(\"Cluster \", cluster)) %>% \n  ggplot(aes(.value)) +\n  stat_histinterval() +\n  facet_wrap(vars(cluster, .variable), ncol = 2, scales = \"free\") +\n  labs(\n    title = \"Posterior of center and standard deviation of clusters 1 & 2\",\n    y = NULL,\n    x = NULL\n  )\n\n\n\n\n\nOne quick and dirty way (which has nice theoretical properties we will see in Chapter 5), is to use the mean of the posterior distributions. Below we overlay the Normal density functions, using the mean of the posterior distributions as the chosen parameters, with our observed data:\n\n\n\ndistdata <- fit %>% \n  spread_draws(mu[cluster], sigma[cluster], theta[cluster]) %>% \n  mean_hdci() %>% \n  mutate(\n    cluster = as_factor(cluster),\n    nest(tibble(x = seq(20, 300, length.out = 500)))\n    ) %>% \n  mutate(\n    data = pmap(\n      list(data, mu, sigma, theta),\n      function(data, mu, sigma, theta) \n        mutate(data, dens = theta * dnorm(x, mean = mu, sd = sigma))\n      )\n  ) %>% \n  unnest() \n\ndistdata %>% \n  ggplot(aes(x = x)) +\n  geom_histogram(\n    data = data, \n    aes(y = stat(density)), color = \"black\", fill = \"white\"\n    ) +\n  geom_ribbon(aes(ymin = 0, ymax = dens, fill = cluster), alpha = 0.5) +\n  labs(\n    title = \"Visualizing Clusters using posterior-mean parameters\",\n    y = NULL,\n    x = NULL\n  ) +\n  scale_fill_viridis_d()\n\n\n\n\nReturning to Clustering: Prediction\n\nWe can try a less precise, but much quicker method. We will use Bayes’ Theorem for this. As you’ll recall, Bayes’ Theorem looks like:\n\n\\[\nP(A|X) = \\frac{P(X|A)P(A)}{P(X)} \n\\]\n\nFor a particular sample set of parameters for our posterior distribution, (\\(\\mu_1,\\sigma_1,\\mu_2,\\sigma_2,\\theta\\)), we are interested in asking, “Is the probability that \\(x\\) is in the cluster 1 greater than the probability it is in cluster 0?” where the probability is dependent on the chosen parameters:\n\n\\[\n\\frac{P(x = ?|L_x = 1)P(L_x=1)}{P(x=?)} > \\frac{P(x = ?|L_x = 2)P(L_x=2)}{P(x=?)} \n\\]\n\nSince the denominators are equal, they can be ignored:\n\n\\[\nP(x = ?|L_x = 1)P(L_x=1) > P(x = ?|L_x = 2)P(L_x=2)\n\\] This is what you’ll see in the generated quantities block but instead on the log space. There is likely a more precise way to estimate the probability of the data points belonging to each cluster. I think it would be similar to what was done in the Chapter 1 model for the change point detection.\n\n\ndataorig <- data %>% \n  mutate(i = row_number())\n\nprobassign <- fit %>% \n  gather_draws(yrep[i]) %>% \n  mean_hdci() %>% \n  left_join(dataorig)\n\nprobassign %>% \n  ggplot(aes(x = x, y = .value)) +\n  geom_point(aes(color = .value)) +\n  scale_color_viridis_c() +\n  labs(\n    title = \"Probability of data point belonging to cluster 0\",\n    y = \"probability\",\n    x = \"value of data point\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n",
    "preview": "bayes-hackr/2021-01-08-bayes-hackr-ch3/bayes-hackr-ch3_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-03-18T22:00:14-05:00",
    "input_file": {}
  },
  {
    "path": "bayes-hackr/2021-01-09-bayes-hackr-ch4/",
    "title": "Chapter 4",
    "description": "Reproducing Chapter 4 of Bayesian Methods for Hackers in R + Stan",
    "author": [
      {
        "name": "J. Duncan",
        "url": {}
      }
    ],
    "date": "2021-01-08",
    "categories": [],
    "contents": "\n4.3 The Disorder of Small Numbers\n4.3.3 Example: How to Sort Reddit Comments\nThe original post:\n\n\nknitr::include_graphics(\"https://i.imgur.com/OYsHKlH.jpg\")\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(RedditExtractoR)\nlibrary(tidybayes)\n\nreddit_thread <- reddit_content(\n  \"https://www.reddit.com/r/pics/comments/1w454i/deleted_by_user/\"\n  ) %>% \n  as_tibble()\n\nvote_data <- reddit_thread %>% \n  mutate(\n    ups = round((upvote_prop * comment_score)/(2 * upvote_prop - 1)),\n    upvotes = if_else(upvote_prop != 0.5, ups, round(comment_score / 2)),\n    downvotes = upvotes - comment_score,\n    total_votes = upvotes + downvotes\n  ) %>% \n  select(comment, comment_score, upvotes, downvotes, total_votes) %>% \n  arrange(desc(comment_score)) %>% \n  filter(comment_score > 1)\n\n\n\n\n\ndat_lists <- vote_data %>% \n  group_by(comment) %>% \n  nest() %>% \n  mutate(data_list = map(data, compose_data))\n\n\n\n\n\nmod <- cmdstanr::cmdstan_model(\"models/ch4-mod.stan\")\nmod$print()\n\n\ndata {\n  int<lower=0> n;\n  int upvotes[n];\n  int total_votes[n];\n}\n\nparameters {\n  real<lower=0,upper=1> upvote_ratio;\n}\n\nmodel {\n  upvote_ratio ~ uniform(0, 1);\n  upvotes ~ binomial(total_votes, upvote_ratio);\n}\n\n\n\nfits <- dat_lists %>% \n  mutate(\n    fit = map(\n      data_list, \n      ~ mod$sample(\n        data = .x,\n        seed = 123,\n        chains = 2,\n        parallel_chains = 2,\n        refresh = 0\n        )\n      )\n    )\n\n\n\nNow for visualizing some of these:\n\n\ntop_dists <- fits %>% \n  unnest(data) %>% \n  filter(\n    str_detect(comment, \"Sly Cooper\") ||\n      str_detect(comment, \"Dammit Elsa\") ||\n      str_detect(comment, \"Duratray\") ||\n      str_detect(comment, \"Actually it does\")\n  ) %>% \n  mutate(\n    draws = map(fit, ~ posterior::as_draws_df(.x$draws())),\n    brief = str_sub(comment, start = 1, end = 76),\n    description = paste0(\"(\", upvotes, \" up:\", downvotes, \" down): \", brief)\n    ) %>% \n  select(description, draws) %>% \n  unnest()\n\n\n\nNow for the histograms:\n\n\ntheme_set(theme_tidybayes())\n\nleast_plaus <- top_dists %>% \n  group_by(description) %>% \n  median_qi(upvote_ratio, .width = 0.95) %>% \n  select(description, .lower)\n  \ntop_dists %>% \n  ggplot(aes(x = upvote_ratio)) +\n  stat_histinterval(slab_color = \"gray45\") +\n  facet_wrap(~ description, ncol = 1) +\n  geom_vline(data = least_plaus, aes(xintercept = .lower), linetype = \"dashed\") +\n  labs(\n    y = NULL,\n    x = \"Probability of Upvotes\"\n  )\n\n\n\n\nSorting all distributions by 95% least plausible values:\n\n\nall_dists <- fits %>% \n  mutate(\n    draws = map(fit, ~ posterior::as_draws_df(.x$draws())),\n    brief = str_sub(comment, start = 1, end = 50),\n    brief = str_remove_all(brief, \"\\n\") # remove new lines\n    ) %>% \n  select(brief, draws) %>% \n  unnest(draws) %>% \n  group_by(brief) %>% \n  median_qi(upvote_ratio, .width = c(0.95)) %>% \n  mutate(\n    brief = as_factor(brief),\n    brief = fct_reorder(brief, .lower)\n  ) %>% \n  top_n(40, .lower)\n\n\n\n\n\nall_dists %>% \n  ggplot(aes(x = upvote_ratio, y = brief)) +\n  geom_pointinterval(aes(xmin = .lower, xmax = .upper)) +\n  labs(\n    y = NULL,\n    x = \"Probability of Upvotes\"\n  )\n\n\n\n\n\n\n\n",
    "preview": "https://i.imgur.com/OYsHKlH.jpg",
    "last_modified": "2022-03-18T22:00:14-05:00",
    "input_file": {}
  },
  {
    "path": "bayes-hackr/2021-01-10-bayes-hackr-ch5/",
    "title": "Chapter 5",
    "description": "Reproducing Chapter 5 of Bayesian Methods for Hackers in R + Stan",
    "author": [
      {
        "name": "J. Duncan",
        "url": {}
      }
    ],
    "date": "2021-01-08",
    "categories": [],
    "contents": "\n5.2 Loss Functions\n5.2.2 Example: Optimizing for the Showcase on The Price Is Right\nWe can start by visualizing some priors:\n\n\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(posterior)\nlibrary(patchwork)\ntheme_set(theme_tidybayes())\n\ntribble(\n  ~var, ~mu, ~sd,\n  \"historical total prices\", 35000, 7500,\n  \"snowblower price guess\", 3000, 500,\n  \"trip price guess\", 12000, 3000\n  ) %>% \n  ggplot() +\n  stat_dist_halfeye(\n    aes(dist = distributional::dist_normal(mu = mu, sigma = sd)),\n    normalize = \"panels\",\n    orientation = \"horizontal\"\n  ) +\n  facet_wrap(~var, ncol = 1) +\n  labs(\n    y = NULL,\n    x = NULL\n  )\n\n\n\n\nThere’s no data block here. We’re simply playing with priors which is kind of cool.\n\n\nmod <- cmdstanr::cmdstan_model(\"models/ch5-mod1.stan\")\nmod$print()\n\n\nparameters {\n  real true_price;\n  real prize_1;\n  real prize_2;\n}\n\ntransformed parameters {\n  real price_estimate;\n  price_estimate = prize_1 + prize_2;\n}\n\nmodel {\n  // priors\n  true_price ~ normal(35000, 7500);\n  prize_1 ~ normal(3000, 500);\n  prize_2 ~ normal(12000, 3000);\n  // updated price using priors of individual prizes\n  true_price ~ normal(price_estimate, 3000);\n}\n\nfit <- mod$sample(\n  seed = 123,\n  chains = 4,\n  parallel_chains = 2,\n  refresh = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 chains, at most 2 in parallel...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.1 seconds.\nChain 4 finished in 0.1 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.5 seconds.\n\nNow to visualize the total_price estimate:\n\n\n# https://mpopov.com/blog/2020/09/07/pivoting-posteriors/\ntidy_draws.CmdStanMCMC <- function(model, ...) {\n  return(as_draws_df(model$draws()))\n}\n\n\n\nNow visualizing the prior information versus the posterior price estimate:\n\n\npriorp <- ggplot() +\n  stat_dist_halfeye(\n    aes(dist = distributional::dist_normal(mu = 35000, sigma = 7500)),\n    .width = 0.25,\n    orientation = \"horizontal\"\n  ) +\n  xlim(5000, 40000) +\n  labs(\n    title = \"Prior distribution of suite price\",\n    y = NULL,\n    x = NULL\n  )\n\npostp <- fit %>% \n  gather_draws(true_price) %>% \n  ggplot() +\n  stat_histinterval(aes(x = .value), .width = 0.25) +\n  xlim(5000, 40000) +\n  labs(\n    title = \"Posterior of the true price estimate\",\n    y = NULL,\n    x = NULL\n  )\n\npriorp / postp\n\n\n\n\n\n\n# with util function\nrisks <- seq(30000, 150000, length.out = 6)\nguesses <- seq(5000, 50000, length.out = 70)\n\n\n\nI prefer the above method of just writing the utility function in Stan and using it to estimate the expected loss. However, there’s a limitation for the optimization process this way. It’s only as granular as the inputs we send to Stan. We could increase the resolution of guesses here and get something more accurate or just keep as is and select the best guess in our set of 70 guesses.\nYou can use the optim function to get a better choice using optimization by just using the posterior within the R environment. Something more like this example which uses the posterior_predict function from the brms package. This is also better for scale once we start having more dimensions.\nDefine the loss function using the true_price posterior distribution\n\n\nshowdown_loss <- function(guess, true_price, risk){\n  loss <- case_when(\n    true_price$.value < guess ~ risk,\n    abs(true_price$.value - guess) <= 250 ~ -2 * abs(true_price$.value),\n    TRUE ~ abs(true_price$.value - guess - 250)\n  )\n  return(mean(loss))\n}\n\n\n\n\n\npost_df <- gather_draws(fit, true_price)\n\ndat <- crossing(guesses, risks) %>% \n  mutate(nest(post_df)) %>% \n  mutate(\n    loss = pmap_dbl(\n      list(guesses, data, risks),\n      ~ showdown_loss(..1, ..2, ..3)\n      )\n    ) %>% \n  select(guesses, risks, loss)\n\np <- dat %>% \n  ggplot(aes(x = guesses, y = loss, color = ordered(risks))) + \n  geom_line() + \n  xlim(5000, 30000) + \n  scale_color_viridis_d(\n    name = \"Risk parameter\",\n    labels = risks\n    ) +\n  labs(\n    title = \"Expected loss of different guesses\",\n    subtitle = \"various risk-levels of overestimating\",\n    x = \"price bid\",\n    y = \"expected loss\"\n  ) \np\n\n\n\n\nMinimizing our losses\n\n\noppnts <- tibble(risks) %>% \n  mutate(nest(post_df)) %>% \n  mutate(\n    opt = map2(data, risks, ~ optim(\n      5000,\n      fn = function(guess) showdown_loss(guess, .x, .y)\n    ))\n  ) %>% \n  mutate(\n    opt_tidy = map(opt, broom::tidy),\n    opt_glance = map(opt, broom::glance)\n  ) %>% \n  unnest(opt_tidy, opt_glance) %>% \n  select(risks, starts_with(\"value\")) %>% \n  rename(guesses = value, loss = value1)\n\np + geom_vline(\n  data = oppnts, \n  aes(xintercept = guesses, color = ordered(risks)), \n  linetype = \"dashed\"\n  ) + \n  scale_color_viridis_d(\n    name = \"Bayes action at risk:\",\n    labels = risks\n    ) +\n  labs(\n    title = \"Expected loss & Bayes actions of different guesses\",\n    subtitle = \"various risk-levels of overestimating\",\n    x = \"price bid\",\n    y = \"expected loss\"\n  ) \n\n\n\n\n5.3 Machine Learning via Bayesian Methods\nExample: Financial Prediction\n\n\nstock_loss <- function(true_return, yhat, alpha = 100.){\n  loss <- if_else(\n    true_return * yhat < 0,\n    alpha * yhat^2 - sign(true_return) * yhat + abs(true_return),\n    abs(true_return - yhat)\n    )\n  return(loss)\n}\n\n\n\n\n\npred <- seq(-0.04, 0.12, length.out = 75)\n\npred_df <- tibble(pred) %>% \n  mutate(\n    `true_0.05` = stock_loss(0.05, pred),\n    `true_-0.02` = stock_loss(-0.02, pred)\n    ) %>% \n  pivot_longer(-pred, names_to = \"loss\", names_prefix = \"true_\")\n\npred_df %>% \n  ggplot(aes(x = pred, y = value, color = loss)) +\n  geom_line() +\n  xlim(-0.04, .12) +\n  ylim(0, 0.25) +\n  geom_vline(aes(xintercept = 0.0), linetype = \"dashed\") +\n  labs(\n    title = \"Stock returns loss if true value = 0.05, -0.02\",\n    y = \"loss\",\n    x = \"prediction\"\n  ) +\n  scale_color_viridis_d(name = \"If true value = \") \n\n\n\n\n\nWe will perform a regression on a trading signal that we believe predicts future returns well. Our dataset is artificial, as most financial data is not even close to linear. Below, we plot the data along with the least-squares line.\n\n\n\n## Code to create artificial data\nset.seed(123)\nN <- 100\nX <- 0.025 * rnorm(N)\nY <- 0.5 * X + 0.01 * rnorm(N)\nartdat <- tibble(X, Y)\n\nls_coef_ <- cov(X, Y) / var(X)\nls_intercept <- mean(Y) - ls_coef_ * mean(X)\n\nartdat %>% \n  ggplot(aes(X, Y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Empirical returns vs trading signal\",\n    x = \"trading signal\",\n    y = \"returns\"\n  )\n\n\n\n\n\n\ndat_list <- compose_data(artdat)\n\ntrading_signals <- seq(min(X), max(X), length.out = 50)\ndat_list[[\"trading_signals\"]] <- trading_signals\n\nmod2 <- cmdstanr::cmdstan_model(\"models/ch5-mod2.stan\")\nmod2$print()\n\n\ndata {\n  int<lower=0> n;\n  vector[n] X;\n  vector[n] Y;\n  vector[50] trading_signals;\n}\n\nparameters {\n  real beta;\n  real alpha;\n  real<lower=0> std;\n}\n\nmodel {\n  alpha ~ normal(0, 100);\n  beta ~ normal(0, 100);\n  std ~ uniform(0, 100);\n  Y ~ normal(alpha + beta * X, std);\n}\n\ngenerated quantities {\n   vector[50] outcomes;\n   for (i in 1:50)\n     outcomes[i] = normal_rng(alpha + beta * trading_signals[i], std);\n}\n\nfit2 <- mod2$sample(\n  data = dat_list,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.7 seconds.\nChain 2 finished in 0.7 seconds.\nChain 4 finished in 0.7 seconds.\nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 0.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 0.8 seconds.\n\nfit2\n\n\n    variable   mean median   sd  mad     q5    q95 rhat ess_bulk\n lp__        408.34 408.67 1.23 1.03 405.89 409.68 1.00     4354\n beta          0.48   0.48 0.04 0.04   0.41   0.55 1.00     6048\n alpha         0.00   0.00 0.00 0.00   0.00   0.00 1.00    15685\n std           0.01   0.01 0.00 0.00   0.01   0.01 1.00     6125\n outcomes[1]  -0.03  -0.03 0.01 0.01  -0.05  -0.01 1.00    11571\n outcomes[2]  -0.03  -0.03 0.01 0.01  -0.04  -0.01 1.00    11097\n outcomes[3]  -0.03  -0.03 0.01 0.01  -0.04  -0.01 1.00    11161\n outcomes[4]  -0.03  -0.03 0.01 0.01  -0.04  -0.01 1.00    11186\n outcomes[5]  -0.02  -0.02 0.01 0.01  -0.04  -0.01 1.00    11457\n outcomes[6]  -0.02  -0.02 0.01 0.01  -0.04  -0.01 1.00    11457\n ess_tail\n     5737\n     5720\n     9136\n     5406\n    11642\n    11396\n    11199\n    11520\n    11194\n    11554\n\n # showing 10 of 54 rows (change via 'max_rows' argument)\n\nVisualizing the marginal distributions:\n\n\ntidy_post <- gather_draws(fit2, alpha, beta, std) \n  \ntidy_post %>% \n  ggplot(aes(x = .value)) +\n  stat_histinterval(normalize = \"panels\", show_interval = FALSE) + \n  facet_wrap(~.variable, ncol = 1, scales = \"free\") +\n  labs(\n    title = \"Marginal Distributions\", \n    y = NULL,\n    x = NULL\n  )\n\n\n\n\nNow for incorporating the loss function into our predictions:\n\n\ntrading_signals <- seq(min(X), max(X), length.out = 50)\ndat_list[[\"trading_signals\"]] <- trading_signals\n\nmod2_1 <- cmdstanr::cmdstan_model(\"models/ch5-mod2-wfunc.stan\")\nmod2_1$print()\n\n\nfunctions {\n  int sign(real x) {\n    return x < 0 ? -1 : 1;\n  }\n  \n  real stock_loss(real true_return, real yhat) {\n    real alpha = 100;\n    if (true_return * yhat < 0)\n      return(alpha * yhat^2 - sign(true_return) * yhat + fabs(true_return));\n    else\n      return(fabs(true_return - yhat));\n  }\n}\n\ndata {\n  int<lower=0> n;\n  vector[n] X;\n  vector[n] Y;\n  vector[50] trading_signals;\n}\n\nparameters {\n  real beta;\n  real alpha;\n  real<lower=0> std;\n}\n\nmodel {\n  alpha ~ normal(0, 100);\n  beta ~ normal(0, 100);\n  std ~ uniform(0, 100);\n  Y ~ normal(alpha + beta * X, std);\n}\n\ngenerated quantities {\n   vector[50] outcomes;\n   vector[50] util;\n   \n   for (i in 1:50){\n     outcomes[i] = normal_rng(alpha + beta * trading_signals[i], std);\n     util[i] = stock_loss(trading_signals[i], outcomes[i]);\n   }\n}\n\nfit3 <- mod2_1$sample(\n  data = dat_list,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 0.8 seconds.\nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 0.9 seconds.\nChain 3 finished in 0.9 seconds.\nChain 4 finished in 0.9 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.9 seconds.\nTotal execution time: 1.0 seconds.\n\nbaction <- fit3 %>% \n  gather_draws(util[i])\n  \ntibble(trading_signals) %>% \n  rowid_to_column(var = \"i\") %>% \n  right_join(baction) %>% \n  ggplot(aes(x = trading_signals)) +\n  stat_lineribbon(aes(y = .value), .width = c(.99, .95, .8, .5), color = \"#08519C\") +\n  scale_fill_brewer()\n\n\n\n\nWe’re able to see the issue with predictions close to zero from the chart above. Given there are many returns that could be positive or negative in this range we see a spike in potential risk or loss. In this case our optimization should instead predict 0 to take no position. This quote from the book explains this all well:\n\nWhat is interesting about the above graph is that when the signal is near 0, and many of the possible returns outcomes are possibly both positive and negative, our best (with respect to our loss) prediction is to predict close to 0, hence take on no position. Only when we are very confident do we enter into a position. I call this style of model a sparse prediction, where we feel uncomfortable with our uncertainty so choose not to act. (Compare with the least-squares prediction which will rarely, if ever, predict zero).\n\nI think the only way we can optimize continuous decisions is to keep the utility/loss function all in the R session. I want to include it in Stan because it kind of wraps it all up nicely but I’m not sure how to minimize/maximize the loss functions here. In the Stan manual it says for \\(k\\) discrete actions:\n\nIt only remains to make the decision k with highest expected utility, which will correspond to the choice with the highest posterior mean for util[k]. This can be read off of the mean column of the Stan’s summary statistics or accessed programmatically through Stan’s interfaces.\n\nThen the following regarding continuous decisions:\n\nIn these cases, the continuous choice can be coded as data in the Stan program. Then the expected utilities may be calculated. In other words, Stan can be used as a function from a choice to expected utilities. Then an external optimizer can call that function.\n\n\n\nypred <- fit2 %>% \n  gather_draws(outcomes[i]) %>% \n  nest()\n\nbayesact <- ypred %>% \n  mutate(\n    opt = map(data, ~ optim(\n      0,\n      fn = function(yhat) stock_loss(.x$.value, yhat, alpha = 500) %>% mean()\n    ))\n  ) %>% \n  select(-data) %>% \n  mutate(\n    opt_tidy = map(opt, broom::tidy),\n    opt_glance = map(opt, broom::glance)\n  ) %>% \n  unnest(opt_tidy, opt_glance) %>% \n  rename(true_return = value, loss = value1) %>% \n  select(i, true_return, loss) %>% \n  ungroup()\n\n\n\nLet’s visualize the predictions now:\n\n\nols <- tibble(trading_signals) %>% \n  rowid_to_column(var = \"i\") %>% \n  mutate(pred = ls_coef_ * trading_signals + ls_intercept)\n\nbayesact %>% \n  left_join(ols) %>% \n  ggplot(aes(x = trading_signals)) +\n  geom_line(aes(y = true_return, color = \"Bayes action\")) +\n  geom_line(aes(y = pred, color = \"Least-squares\")) +\n  geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n  labs(\n    title = \"Least-squares prediction vs. Bayes action prediction\",\n    x = \"trading signal\",\n    y = \"prediction\"\n  ) +\n  scale_color_viridis_d(name = NULL)\n\n\n\n\n5.3.2 Example: Kaggle Contest on Observing Dark Worlds\n\n\nlibrary(ggforce)\n\nsky3 <- read_csv(\"data/Train_Skies/Training_Sky3.csv\")\n\nsize_multiplier <- 25\n\nsky3prep <- sky3 %>% \n  mutate(\n    d = sqrt(e1^2 + e2^2),\n    a = (1.0 / (1 - d)) * size_multiplier,\n    b = (1.0 / (1 + d)) * size_multiplier,\n    theta = atan2(e2, e1) * 0.5\n  )\n\np2 <- sky3prep %>% \n  ggplot() +\n  geom_ellipse(\n    aes(x0 = x, y0 = y, a = a, b = b, angle = theta), \n    alpha = 0.4,\n    fill = 'cyan4', \n    colour = 'cyan4'\n    )\n\np2\n\n\n\n\n\n\ndat_list2 <- list(\n  n = nrow(sky3),\n  cart_pos = rbind(sky3$x, sky3$y),\n  ellip_pos = rbind(sky3$e1, sky3$e2)\n)\n\n\n\nThanks to some help from the Stan community: https://discourse.mc-stan.org/t/help-with-vectorizing-stan-program/19957\n\n\nmod3 <- cmdstanr::cmdstan_model(\"models/ch5-mod3.stan\")\nmod3$print()\n\n\nfunctions {\nreal f_distance(vector gxy_pos, vector halo_pos, real c) {\n  return fmax(distance(gxy_pos, halo_pos), c);\n}\n\nvector tangential_distance(vector glxy_position, vector halo_position) {\n  vector[2] delta = glxy_position - halo_position;\n  real t = (2 * atan(delta[2] / delta[1]));\n  return to_vector({-cos(t), -sin(t)});\n}\n}\n\ndata {\n  int<lower=0> n;\n  matrix[2, n] cart_pos; // x,y coordinates of galaxy position\n  matrix[2, n] ellip_pos; // a measure of ellipticity\n}\n\nparameters {\n  real<lower=40.0,upper=180.0> exp_mass_large;\n  vector<lower=0,upper=4200.0>[2] halo_position;\n}\n\ntransformed parameters {\n  real mass_large = log(exp_mass_large); // one large halo\n}\n\nmodel {\n  vector[2] mu; \n  \n  for (i in 1:n) {\n    mu = mass_large / f_distance(cart_pos[:, i], halo_position, 240.0) * \n      tangential_distance(cart_pos[:, i], halo_position); \n    ellip_pos[, i] ~ normal(mu, 0.05); // x-y coordinates\n  }\n}\n\n# sample with MCMC\nfit4 <- mod3$sample(\n  data = dat_list2,\n  seed = 123,\n  chains = 4,\n  parallel_chains = 4,\n  refresh = 1000,\n  iter_warmup = 1000,\n  iter_sampling = 3000\n)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \nChain 3 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 3 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 1 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 2 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 2 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 4 Iteration: 1000 / 4000 [ 25%]  (Warmup) \nChain 4 Iteration: 1001 / 4000 [ 25%]  (Sampling) \nChain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \nChain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 1 finished in 52.4 seconds.\nChain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 2 finished in 53.1 seconds.\nChain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 3 finished in 53.3 seconds.\nChain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \nChain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \nChain 4 finished in 59.2 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 54.5 seconds.\nTotal execution time: 59.8 seconds.\n\nfit4$summary()\n\n\n# A tibble: 5 x 10\n  variable    mean  median      sd     mad      q5     q95  rhat\n  <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1 lp__     -1.18e4 -1.18e4  1.33    1.19   -1.18e4 -1.18e4  1.00\n2 exp_mas…  1.73e2  1.75e2  7.13    5.31    1.58e2  1.80e2  1.00\n3 halo_po…  2.33e3  2.34e3 32.7    33.0     2.28e3  2.39e3  1.00\n4 halo_po…  1.19e3  1.19e3 56.3    48.7     1.08e3  1.26e3  1.00\n5 mass_la…  5.15e0  5.16e0  0.0431  0.0302  5.06e0  5.19e0  1.00\n# … with 2 more variables: ess_bulk <dbl>, ess_tail <dbl>\n\nVisualizing the halo location:\n\n\nhalo_post <- fit4 %>% \n  spread_draws(halo_position[coord]) %>% \n  pivot_wider(names_from = coord, values_from = halo_position) %>% \n  rename(x = `1`, y = `2`)\n\ntrue_loc <- read_csv(\"data/Training_halos.csv\") %>% \n  filter(SkyId == \"Sky3\") %>% \n  rename(x = halo_x1, y = halo_y1)\n\np2 + \n  geom_point(data = halo_post, aes(x = x, y = y), alpha = 0.015, color = \"black\") +\n  geom_point(data = true_loc, aes(x = x, y = y), color = \"orange\")\n\n\n\n\nA closer look at the true location parameters:\n\n\ntrue_loc <- read_csv(\"data/Training_halos.csv\") %>% \n  filter(SkyId == \"Sky3\") %>% \n  rename(`1` = halo_x1, `2` = halo_y1) %>% \n  select(`1`, `2`) %>% \n  pivot_longer(`1`:`2`, names_to = \"coord\") %>% \n  mutate(coord = as.integer(coord))\n\nfit4 %>% \n  spread_draws(halo_position[coord]) %>% \n  left_join(true_loc) %>% \n  ggplot() +\n  stat_histinterval(aes(x = halo_position), show_interval = FALSE, breaks = 40) +\n  geom_vline(aes(xintercept = value), linetype = \"dashed\") +\n  facet_wrap(~ coord, ncol = 1, scales = \"free\") \n\n\n\n\n\n\n\n",
    "preview": "bayes-hackr/2021-01-10-bayes-hackr-ch5/halo-example.png",
    "last_modified": "2022-03-18T22:00:14-05:00",
    "input_file": {}
  }
]
